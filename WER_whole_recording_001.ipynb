{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WER on single recording end to end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from graphviz import Digraph\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Corpus into Recordings $\\langle A_i,T_i \\rangle$ and Transcription Splits $\\langle A_{i,j}, T_{i,j} \\rangle$ within Recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cfg import Cfg\n",
    "import split_corpus_into_recordings_and_splits\n",
    "C = Cfg('NIST', 8000, 'amharic') \n",
    "split_corpus_into_recordings_and_splits.diagram(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RecordingCorpus import RecordingCorpus\n",
    "from multiprocessing import Pool\n",
    "if __name__ == '__main__':\n",
    "    with Pool(16) as pool:\n",
    "        recordings = RecordingCorpus(C, pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SplitCorpus import SplitCorpus\n",
    "splits=SplitCorpus.from_recordings(C, recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsplit $A_{i,j}$ on silence and apportion text to trimmed chunks by word sizes in $T_{i,j} = \\langle w_{i,j,k} \\rangle$ where $w_{i,j,k}=\\langle g_{i,j,k,l} \\rangle$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subsplit_Aij_on_silence_and_apportion_text_by_size\n",
    "subsplit_Aij_on_silence_and_apportion_text_by_size.diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SubSplitCorpus import SubSplitCorpus"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "subsplits=SubSplitCorpus(splits, min_words=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('bfgpu.pkl', 'rb') as f:\n",
    "    subsplits=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ASR NN on subsplits $A_{i,j,k} \\to P_{i,j,k} \\approx T_{i,j,k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_ASR_NN_on_subsplits\n",
    "train_ASR_NN_on_subsplits.diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['IN_JUPYTER']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASR_NN import ASR_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ASR = ASR_NN(C);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ASR.load_model();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ASR.load_training_set(subsplits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_output = model_ASR.train(subsplits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_scores = model_ASR.score(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up GPU memory for next phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "del model_ASR\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate $P_{i,j,k}$ giving $P_{i,j} = P_{i,j,1}\\|\\cdots\\|P_{i,j,-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concatenate_Pikj_giving_Pij\n",
    "concatenate_Pikj_giving_Pij.diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pijk=ASR_output.pred\n",
    "Pij=ASR_NN_trainer.concatenate(Pijk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train text-to-text corrector on both $P_{i,j,k} \\to Q_{i,j,k} \\approx T_{i,j,k}$ and $P_{i,j} \\to Q_{i,j} \\approx T_{i,j}$ and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_text_to_text_corrector_on_Pij_and_Pijk_and_score\n",
    "train_text_to_text_corrector_on_Pij_and_Pijk_and_score.diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsplit $A_{i,j}$ on silence alone retaining timecode $(s_{i,j,k},e_{i,j,k})$ giving $A_{i,j} = \\langle (\\alpha_{i,j,k}, (s_{i,j,k},e_{i,j,k})) \\rangle$ so that $\\alpha_{i,j,k} = A_{i,j}[s_{i,j,k}:e_{i,j,k}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subsplit_Aij_on_silence_retaining_timecode\n",
    "subsplit_Aij_on_silence_retaining_timecode.diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer $(\\alpha_{i,j,k}, (s_{i,j,k},e_{i,j,k})) \\xrightarrow{ASR} p_{i,j,k} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import infer_aijk_giving_pijk\n",
    "infer_aijk_giving_pijk.diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate $p_{i,j,k} \\to p_{i,j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concatenate_pikj_giving_pij\n",
    "concatenate_pikj_giving_pij.diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer $p_{i,j} \\xrightarrow{TT} (q_{i,j},(s_{i,j,0},e_{i,j,-1}))$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import infer_pij_giving_qij\n",
    "infer_pij_giving_qij.diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate $\\langle \\langle (q_{i,j,k},(s_{i,j,k},e_{i,j,k})) \\rangle \\rangle $ giving transcript $Q_i = \\langle (q_{i,j}, (s_{i,j,0},e_{i,j,-1})) \\rangle$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concatenate_qijk_giving_Qi\n",
    "concatenate_qijk_giving_Qi.diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save transcript $Q_i$ in .CTM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import save_transcript_Qi_in_CTM_format\n",
    "save_transcript_Qi_in_CTM_format.diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score $\\langle T_i,Q_i\\rangle$ using `sclite` for each recording individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import score_TiQi_using_sclite_per_recording\n",
    "score_TiQi_using_sclite_per_recording.diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score $\\langle T_i,Q_i\\rangle$ using `sclite` collectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import score_TiQi_using_sclite_on_all_recordings_together\n",
    "score_TiQi_using_sclite_on_all_recordings_together.diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openasr",
   "language": "python",
   "name": "openasr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
