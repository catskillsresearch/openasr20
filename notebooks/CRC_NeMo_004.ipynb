{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum clip size"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from glob import glob\n",
    "\n",
    "files=glob('NIST/openasr20_amharic/build/audio_split/*.wav')+glob('NIST/openasr20_amharic/dev/audio_split/*.wav')\n",
    "\n",
    "files[1]\n",
    "\n",
    "def seconds_in_file(fn):\n",
    "    [start,end]=fn.split('/')[-1].split('.')[0].split('_')[-2:]\n",
    "    return (float(end)-float(start))/16000\n",
    "\n",
    "FS=[seconds_in_file(fn) for fn in files]\n",
    "\n",
    "max(FS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train step 1: Bootstrap from pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import pickle, os, warnings, sys, random, logging, librosa, json, nemo\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from Cfg import Cfg\n",
    "from reshuffle_samples import reshuffle_samples\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "import os, datetime\n",
    "from load_pretrained_amharic_model import load_pretrained_amharic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C, model, params = load_pretrained_amharic_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Phase 2: K-fold validation more or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import os, datetime\n",
    "from Cfg import Cfg\n",
    "from load_pretrained_amharic_model import load_pretrained_amharic_model\n",
    "C, model, params = load_pretrained_amharic_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir='save/nemo_amharic'\n",
    "\n",
    "class ModelCheckpointAtEpochEnd(pl.callbacks.ModelCheckpoint):\n",
    "    def on_epoch_end(self, trainer, pl_module):\n",
    "        metrics = trainer.callback_metrics\n",
    "        metrics['epoch'] = trainer.current_epoch\n",
    "        trainer.checkpoint_callback.on_validation_end(trainer, pl_module)\n",
    "\n",
    "pid=os.getpid()\n",
    "dt=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpointAtEpochEnd(\n",
    "    filepath=model_save_dir+'/amharic_'+f'{dt}_{pid}'+'_{epoch:02d}',\n",
    "    verbose=True,\n",
    "    save_top_k=-1,\n",
    "    save_weights_only=False,\n",
    "    period=1)\n",
    "\n",
    "trainer = pl.Trainer(gpus=[0], max_epochs=200, amp_level='O1', precision=16, checkpoint_callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reshuffle_samples import reshuffle_samples\n",
    "reshuffle_samples(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local test on BUILD -- In Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_lines_load import json_lines_load\n",
    "T=json_lines_load(f'{C.build_dir}/train_manifest.json')\n",
    "V=json_lines_load(f'{C.build_dir}/test_manifest.json')\n",
    "samples=T+V\n",
    "\n",
    "len(samples)\n",
    "\n",
    "S=list(sorted([(x['audio_filepath'],x['text']) for x in samples]))\n",
    "\n",
    "audio_files=[x for x,y in S[0:12]]\n",
    "transcripts=[y for x,y in S[0:12]]\n",
    "\n",
    "pred=model.transcribe(paths2audio_files=audio_files, batch_size=1)\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(zip(transcripts,pred), columns=['gold','pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With save/restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = nemo_asr.models.EncDecCTCModel.load_from_checkpoint('save/nemo_amharic/amharic_20201015_005720_353924_epoch=167.ckpt')\n",
    "model3.cuda(0)\n",
    "pred3=model3.transcribe(paths2audio_files=audio_files, batch_size=1)\n",
    "pd.DataFrame(zip(transcripts,pred3), columns=['gold','pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local test on BUILD -- Out of Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a silence split on DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cfg import Cfg\n",
    "C = Cfg('NIST', 16000, 'amharic', 'dev') \n",
    "\n",
    "from RecordingCorpus import RecordingCorpus\n",
    "from multiprocessing import Pool\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(16) as pool:\n",
    "        recordings = RecordingCorpus(C, pool)\n",
    "\n",
    "from SplitCorpus import SplitCorpus\n",
    "ssplits=SplitCorpus.split_on_silence(C, recordings, 30)\n",
    "\n",
    "import soundfile as sf\n",
    "from tqdm.auto import tqdm\n",
    "F=[]\n",
    "for sample in tqdm(ssplits.artifacts):\n",
    "    (_,root,(start,end))=sample.key\n",
    "    audio = sample.source.value\n",
    "    audio_path=f'{C.audio_split_dir}/{root}_{start}_{end}.wav'\n",
    "    sf.write(audio_path, audio, C.sample_rate)\n",
    "    sample.source.filename=audio_path\n",
    "    F.append(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cfg:\n",
    "\n",
    "    def __init__(self, _stage, _sample_rate, _language, _phase='build', _release='001'):\n",
    "        self.stage = _stage\n",
    "        self.sample_rate = _sample_rate\n",
    "        self.language = _language\n",
    "        self.phase = _phase\n",
    "        self.release = _release\n",
    "        self.data_dir=f'{self.stage}/openasr20_{self.language}'\n",
    "        self.build_dir=f'{self.data_dir}/{self.phase}'\n",
    "        self.audio_split_dir=f'{self.build_dir}/audio_split'\n",
    "        os.system(f'mkdir -p {self.build_dir}')\n",
    "        os.system(f'mkdir -p {self.audio_split_dir}')\n",
    "        self.shipping_dir=f'ship/{self.language}/{self.release}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Cfg('NIST', 16000, 'amharic', 'dev', '101') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=list(sorted(glob(f'{C.audio_split_dir}/*.wav')))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "translations=model.transcribe(paths2audio_files=files, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1353479-1217750)/16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(files[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package for NIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, tarfile\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctms={'_'.join(os.path.basename(fn.split(',')[0]).split('_')[0:7]): [] for fn in files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn,pred in zip(files,translations):\n",
    "   key=os.path.basename(fn)[0:-4].split('_')\n",
    "   ctm='_'.join(key[0:7])\n",
    "   F='_'.join(key[0:6])\n",
    "   channel=key[6]\n",
    "   tstart=float(key[-2])\n",
    "   tend=float(key[-1])\n",
    "   tbeg=tstart/C.sample_rate\n",
    "   tdur=(tend-tstart)/C.sample_rate\n",
    "   chnl='1' if channel=='inLine' else '2'\n",
    "   tokens=pred[0:-1].split(' ')\n",
    "   n_tokens=len(tokens)\n",
    "   dt = tdur/n_tokens\n",
    "   tgrid=np.array([i*dt for i in range(n_tokens)])+tbeg\n",
    "   token_tstart=list(zip(tokens,tgrid))\n",
    "   if ctms[ctm]: start_from = ctms[ctm][-1][2]\n",
    "   for token, tstart in token_tstart:\n",
    "       if token and token[0] not in ['(', '<']:\n",
    "           row=(F,chnl,tstart,dt,token)\n",
    "           ctms[ctm].append(row)\n",
    "for ctm in ctms:\n",
    "   ctms[ctm].sort()\n",
    "shipping_dir=f'ship/{C.language}/{C.release}'\n",
    "Path(shipping_dir).mkdir(parents=True, exist_ok=True)\n",
    "timestamp=datetime.today().strftime('%Y%m%d_%H%M')\n",
    "for ctm in ctms:\n",
    "   fn=f'{C.shipping_dir}/{ctm}.ctm'\n",
    "   with open(fn,'wt', encoding='utf-8') as f:\n",
    "       for row in ctms[ctm]:\n",
    "           line='\\t'.join([str(x) for x in row])\n",
    "           f.write(f\"{line}\\n\")\n",
    "os.chdir(shipping_dir)\n",
    "tar_fn=f'../../catskills_openASR20_dev_{C.language}_{C.release}.tgz'\n",
    "with tarfile.open(tar_fn, \"w:gz\") as tar: \n",
    "    for fn in glob('*.ctm'): \n",
    "        tar.add(fn)\n",
    "os.chdir('../..')\n",
    "print('wrote', tar_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ASR_with_NeMo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "nemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
