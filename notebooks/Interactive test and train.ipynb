{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive train and test with WER in sentence length order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/catskills/Desktop/openasr20/end2end_asr_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['IN_JUPYTER']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, logging, math, os, random, time, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from glob import glob\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.asr.transformer import Transformer, Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import SpectrogramDataset, AudioDataLoader, BucketingSampler\n",
    "from utils.functions import save_model, load_model, init_transformer_model, init_optimizer\n",
    "from utils.lstm_utils import LM\n",
    "from utils.metrics import calculate_metrics, calculate_cer, calculate_wer, calculate_cer_en_zh\n",
    "from utils.optimizer import NoamOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import constant\n",
    "from utils.functions import save_model\n",
    "from utils.optimizer import NoamOpt\n",
    "from utils.metrics import calculate_metrics, calculate_cer, calculate_wer\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch\n",
    "import logging\n",
    "import sys\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language='amharic'\n",
    "stage='NIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = list(sorted(glob(f'{stage}/openasr20_{language}/build/transcription_split/*.txt')))\n",
    "print(len(chunks), 'chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_size(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        return (len(f.read().strip().split(' ')), fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_chunks=list(sorted([chunk_size(fn) for fn in chunks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_chunk_files={x:[] for x,y in size_chunks}\n",
    "for x,y in size_chunks:\n",
    "    size_chunk_files[x].append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_chunk_distribution={x:0 for x,y in size_chunks}\n",
    "for x,y in size_chunks:\n",
    "    size_chunk_distribution[x] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sentences=len(size_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.hist([np.log2(x) for x,y in size_chunks], bins=max(size_chunk_distribution))\n",
    "plt.title(\"Zipf's Law for sentences\")\n",
    "xlabel(\"$\\log_2(|S|)$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[]\n",
    "for text in size_chunk_files[1]:\n",
    "    audio=text.replace('transcription','audio').replace('txt', 'wav')\n",
    "    L.append(f'{audio},{text}')\n",
    "\n",
    "random.shuffle(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_file_path=f'analysis/{language}/size_1.csv'\n",
    "with open(manifest_file_path,'w') as f:\n",
    "    f.write('\\n'.join(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=f'save/{language}_end2end_asr_pytorch_drop0.1_cnn_batch12_4_vgg_layer4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=constant.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.continue_from=None\n",
    "args.cuda = True\n",
    "args.labels_path = f'analysis/{language}/{language}_characters.json'\n",
    "args.lr = 1e-4\n",
    "args.name = f'{language}_end2end_asr_pytorch_drop0.1_cnn_batch12_4_vgg_layer4'\n",
    "args.save_folder = f'save'\n",
    "args.epochs = 5\n",
    "args.save_every = 1\n",
    "args.feat_extractor = f'vgg_cnn'\n",
    "args.dropout = 0.1\n",
    "args.num_layers = 4\n",
    "args.num_heads = 8\n",
    "args.dim_model = 512\n",
    "args.dim_key = 64\n",
    "args.dim_value = 64\n",
    "args.dim_input = 161\n",
    "args.dim_inner = 2048\n",
    "args.dim_emb = 512\n",
    "args.shuffle=True\n",
    "args.min_lr = 1e-6\n",
    "args.k_lr = 1\n",
    "args.sample_rate=8000\n",
    "args.train_manifest_list = [manifest_file_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_conf = dict(sample_rate=args.sample_rate,\n",
    "                  window_size=args.window_size,\n",
    "                  window_stride=args.window_stride,\n",
    "                  window=args.window,\n",
    "                  noise_dir=args.noise_dir,\n",
    "                  noise_prob=args.noise_prob,\n",
    "                  noise_levels=(args.noise_min, args.noise_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.labels_path, 'r') as label_file:\n",
    "    labels = str(''.join(json.load(label_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add PAD_CHAR, SOS_CHAR, EOS_CHAR\n",
    "labels = constant.PAD_CHAR + constant.SOS_CHAR + constant.EOS_CHAR + labels\n",
    "label2id, id2label = {}, {}\n",
    "count = 0\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] not in label2id:\n",
    "        label2id[labels[i]] = count\n",
    "        id2label[count] = labels[i]\n",
    "        count += 1\n",
    "    else:\n",
    "        print(\"multiple label: \", labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant.args.continue_from=f'{model_dir}/best_model.th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant.args.continue_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if constant.args.continue_from:\n",
    "        model, opt, epoch, metrics, loaded_args, label2id, id2label = load_model(\n",
    "            constant.args.continue_from)\n",
    "        start_epoch = epoch  # index starts from zero\n",
    "        verbose = constant.args.verbose\n",
    "else:\n",
    "    model = init_transformer_model(constant.args, label2id, id2label)\n",
    "    opt = init_optimizer(constant.args, model, \"noam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = epoch\n",
    "metrics = None\n",
    "loaded_args = None\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant.USE_CUDA=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SpectrogramDataset(audio_conf, manifest_filepath_list=args.train_manifest_list, label2id=label2id, normalize=True, augment=args.augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\"\n",
    "    Trainer class\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        logging.info(\"Trainer is initialized\")\n",
    "        self.writer = SummaryWriter()\n",
    "\n",
    "    def train(self, model, train_loader, train_sampler, opt, loss_type, start_epoch, num_epochs, label2id, id2label, last_metrics=None):\n",
    "        \"\"\"\n",
    "        Training\n",
    "        args:\n",
    "            model: Model object\n",
    "            train_loader: DataLoader object of the training set\n",
    "            opt: Optimizer object\n",
    "            start_epoch: start epoch (> 0 if you resume the process)\n",
    "            num_epochs: last epoch\n",
    "            last_metrics: (if resume)\n",
    "        \"\"\"\n",
    "        history = []\n",
    "        start_time = time.time()\n",
    "        smoothing = constant.args.label_smoothing\n",
    "\n",
    "        logging.info(\"name \" +  constant.args.name)\n",
    "\n",
    "        training_pass = 0\n",
    "        \n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            sys.stdout.flush()\n",
    "            total_loss, total_cer, total_wer, total_char, total_word = 0, 0, 0, 0, 0\n",
    "\n",
    "            start_iter = 0\n",
    "\n",
    "            scaler = GradScaler()\n",
    "            \n",
    "            logging.info(\"TRAIN\")\n",
    "            model.train()\n",
    "            pbar = tqdm(iter(train_loader), leave=True, total=len(train_loader))\n",
    "            for i, (data) in enumerate(pbar, start=start_iter):\n",
    "                src, tgt, src_percentages, src_lengths, tgt_lengths = data\n",
    "\n",
    "                if constant.USE_CUDA:\n",
    "                    src = src.cuda()\n",
    "                    tgt = tgt.cuda()\n",
    "\n",
    "                opt.zero_grad()\n",
    "\n",
    "                with autocast():\n",
    "                    pred, gold, hyp_seq, gold_seq = model(src, src_lengths, tgt, verbose=False)\n",
    "\n",
    "                    try: # handle case for CTC\n",
    "                        strs_gold, strs_hyps = [], []\n",
    "                        for ut_gold in gold_seq:\n",
    "                            str_gold = \"\"\n",
    "                            for x in ut_gold:\n",
    "                                if int(x) == constant.PAD_TOKEN:\n",
    "                                    break\n",
    "                                str_gold = str_gold + id2label[int(x)]\n",
    "                            strs_gold.append(str_gold)\n",
    "                        for ut_hyp in hyp_seq:\n",
    "                            str_hyp = \"\"\n",
    "                            for x in ut_hyp:\n",
    "                                if int(x) == constant.PAD_TOKEN:\n",
    "                                    break\n",
    "                                str_hyp = str_hyp + id2label[int(x)]\n",
    "                            strs_hyps.append(str_hyp)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        logging.info(\"NaN predictions\")\n",
    "                        continue\n",
    "\n",
    "                    seq_length = pred.size(1)\n",
    "                    sizes = Variable(src_percentages.mul_(int(seq_length)).int(), requires_grad=False)\n",
    "\n",
    "                    loss, num_correct = calculate_metrics(\n",
    "                        pred, gold, input_lengths=sizes, target_lengths=tgt_lengths, smoothing=smoothing, loss_type=loss_type)\n",
    "\n",
    "                    if loss.item() == float('Inf'):\n",
    "                        logging.info(\"Found infinity loss, masking\")\n",
    "                        loss = torch.where(loss != loss, torch.zeros_like(loss), loss) # NaN masking\n",
    "                        continue\n",
    "\n",
    "                    if constant.args.verbose:\n",
    "                         logging.info(\"GOLD\", strs_gold)\n",
    "                         logging.info(\"HYP\", strs_hyps)\n",
    "\n",
    "                    for j in range(len(strs_hyps)):\n",
    "                        strs_hyps[j] = strs_hyps[j].replace(constant.SOS_CHAR, '').replace(constant.EOS_CHAR, '')\n",
    "                        strs_gold[j] = strs_gold[j].replace(constant.SOS_CHAR, '').replace(constant.EOS_CHAR, '')\n",
    "                        cer = calculate_cer(strs_hyps[j].replace(' ', ''), strs_gold[j].replace(' ', ''))\n",
    "                        wer = calculate_wer(strs_hyps[j], strs_gold[j])\n",
    "                        total_cer += cer\n",
    "                        total_wer += wer\n",
    "                        total_char += len(strs_gold[j].replace(' ', ''))\n",
    "                        total_word += len(strs_gold[j].split(\" \"))\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                constant.args.clip = False\n",
    "                if constant.args.clip:\n",
    "                    scaler.unscale_(opt)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), constant.args.max_norm)\n",
    "                \n",
    "                scaler.step(opt)\n",
    "\n",
    "                scaler.update()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                non_pad_mask = gold.ne(constant.PAD_TOKEN)\n",
    "                num_word = non_pad_mask.sum().item()\n",
    "\n",
    "                TRAIN_LOSS=total_loss/(i+1)\n",
    "                CER = total_cer*100/total_char\n",
    "                pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} CER:{:.2f}% LR:{:.7f}\".format(\n",
    "                    (epoch+1), TRAIN_LOSS, CER, opt._rate))\n",
    "                self.writer.add_scalar(\"Loss/train\", TRAIN_LOSS, training_pass+1)\n",
    "                self.writer.add_scalar(\"CER/train\", CER, training_pass+1)\n",
    "                self.writer.add_scalar(\"LR/train\", opt._rate, training_pass+1)\n",
    "                self.writer.flush()\n",
    "                training_pass += 1\n",
    "\n",
    "            logging.info(\"(Epoch {}) TRAIN LOSS:{:.4f} CER:{:.2f}% LR:{:.7f}\".format(\n",
    "                (epoch+1), total_loss/(len(train_loader)), total_cer*100/total_char, opt._rate))\n",
    "\n",
    "            metrics = {}\n",
    "            metrics[\"train_loss\"] = total_loss / len(train_loader)\n",
    "            metrics[\"train_cer\"] = total_cer\n",
    "            metrics[\"train_wer\"] = total_wer\n",
    "            metrics[\"history\"] = history\n",
    "            history.append(metrics)\n",
    "\n",
    "            if epoch % constant.args.save_every == 0:\n",
    "                save_model(model, (epoch+1), opt, metrics,\n",
    "                        label2id, id2label, best_model=False)\n",
    "\n",
    "            save_model(model, (epoch+1), opt, metrics,\n",
    "                        label2id, id2label, best_model=True)\n",
    "\n",
    "            train_sampler.shuffle(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type = args.loss\n",
    "model = model.cuda(0)\n",
    "num_epochs = start_epoch + constant.args.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch, num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 10\n",
    "train_sampler = BucketingSampler(train_data, batch_size=args.batch_size)\n",
    "train_loader = AudioDataLoader(train_data, num_workers=args.num_workers, batch_sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train(model, train_loader, train_sampler, opt, loss_type, start_epoch, num_epochs, label2id, id2label, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = constant.args.label_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = train_loader\n",
    "total_valid_loss, total_valid_cer, total_valid_wer, total_valid_char, total_valid_word = 0, 0, 0, 0, 0\n",
    "for i, (data) in enumerate(valid_loader):\n",
    "    src, tgt, src_percentages, src_lengths, tgt_lengths = data\n",
    "    src = src.cuda()\n",
    "    tgt = tgt.cuda()\n",
    "    with autocast():\n",
    "        pred, gold, hyp_seq, gold_seq = model(src, src_lengths, tgt, verbose=False)\n",
    "\n",
    "    seq_length = pred.size(1)\n",
    "    sizes = Variable(src_percentages.mul_(int(seq_length)).int(), requires_grad=False)\n",
    "\n",
    "    loss, num_correct = calculate_metrics(\n",
    "        pred, gold, input_lengths=sizes, target_lengths=tgt_lengths, smoothing=smoothing, loss_type=loss_type)\n",
    "\n",
    "    if loss.item() == float('Inf'):\n",
    "        logging.info(\"Found infinity loss, masking\")\n",
    "        loss = torch.where(loss != loss, torch.zeros_like(loss), loss) # NaN masking\n",
    "        continue\n",
    "\n",
    "    try: # handle case for CTC\n",
    "        strs_gold, strs_hyps = [], []\n",
    "        for ut_gold in gold_seq:\n",
    "            str_gold = \"\"\n",
    "            for x in ut_gold:\n",
    "                if int(x) == constant.PAD_TOKEN:\n",
    "                    break\n",
    "                str_gold = str_gold + id2label[int(x)]\n",
    "            strs_gold.append(str_gold)\n",
    "        for ut_hyp in hyp_seq:\n",
    "            str_hyp = \"\"\n",
    "            for x in ut_hyp:\n",
    "                if int(x) == constant.PAD_TOKEN:\n",
    "                    break\n",
    "                str_hyp = str_hyp + id2label[int(x)]\n",
    "            strs_hyps.append(str_hyp)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        logging.info(\"NaN predictions\")\n",
    "        continue\n",
    "\n",
    "    for j in range(len(strs_hyps)):\n",
    "        strs_hyps[j] = strs_hyps[j].replace(constant.SOS_CHAR, '').replace(constant.EOS_CHAR, '')\n",
    "        strs_gold[j] = strs_gold[j].replace(constant.SOS_CHAR, '').replace(constant.EOS_CHAR, '')\n",
    "        cer = calculate_cer(strs_hyps[j].replace(' ', ''), strs_gold[j].replace(' ', ''))\n",
    "        wer = calculate_wer(strs_hyps[j], strs_gold[j])\n",
    "        success = 'SUCCESS' if strs_gold[j] == strs_hyps[j] else ''\n",
    "        print(f'[{j}] cer {cer} wer {wer} gold {strs_gold[j]}:{len(strs_gold[j])} hyp {strs_hyps[j]}:{len(strs_hyps[j])} {success}')\n",
    "        total_valid_cer += cer\n",
    "        total_valid_wer += wer\n",
    "        total_valid_char += len(strs_gold[j].replace(' ', ''))\n",
    "        total_valid_word += len(strs_gold[j].split(\" \"))\n",
    "\n",
    "    total_valid_loss += loss.item()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs_gold, strs_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openasr",
   "language": "python",
   "name": "openasr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
