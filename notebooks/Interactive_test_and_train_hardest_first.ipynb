{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive train and test with WER hardest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/catskills/Desktop/openasr20/end2end_asr_pytorch')\n",
    "\n",
    "import os\n",
    "os.environ['IN_JUPYTER']='True'\n",
    "\n",
    "from chunk_size import chunk_size\n",
    "from glob import glob\n",
    "from models.asr.transformer import Transformer, Encoder, Decoder\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from utils import constant\n",
    "from utils.data_loader import SpectrogramDataset, AudioDataLoader, BucketingSampler\n",
    "from utils.functions import save_model, load_model, init_transformer_model, init_optimizer\n",
    "from utils.lstm_utils import LM\n",
    "from utils.metrics import calculate_metrics, calculate_cer, calculate_wer, calculate_cer_en_zh\n",
    "from utils.optimizer import NoamOpt\n",
    "import json, logging, math, os, random, time, torch, sys, random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from Trainer import Trainer\n",
    "\n",
    "language='amharic'\n",
    "stage='NIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_by_wl=f'analysis/{language}/RL1.json'\n",
    "with open(list_by_wl, 'r') as f:\n",
    "    RL=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[y for x,y in RL[0:8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 samples in training set\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(L)} samples in training set')\n",
    "\n",
    "manifest_file_path=f'analysis/{language}/size_1.csv'\n",
    "with open(manifest_file_path,'w') as f:\n",
    "    f.write('\\n'.join(L))\n",
    "\n",
    "model_dir=f'save/{language}_end2end_asr_pytorch_drop0.1_cnn_batch12_4_vgg_layer4'\n",
    "\n",
    "args=constant.args\n",
    "args.continue_from=None\n",
    "args.cuda = True\n",
    "args.labels_path = f'analysis/{language}/{language}_characters.json'\n",
    "args.lr = 0.0000150\n",
    "args.name = f'{language}_end2end_asr_pytorch_drop0.1_cnn_batch12_4_vgg_layer4'\n",
    "args.save_folder = f'save'\n",
    "args.epochs = 5\n",
    "args.save_every = 100\n",
    "args.print_every = 10\n",
    "args.feat_extractor = f'vgg_cnn'\n",
    "args.dropout = 0.1\n",
    "args.num_layers = 4\n",
    "args.num_heads = 8\n",
    "args.dim_model = 512\n",
    "args.dim_key = 64\n",
    "args.dim_value = 64\n",
    "args.dim_input = 161\n",
    "args.dim_inner = 2048\n",
    "args.dim_emb = 512\n",
    "args.shuffle=True\n",
    "args.min_lr = 1e-6\n",
    "args.k_lr = 1\n",
    "args.sample_rate=8000\n",
    "args.train_manifest_list = [manifest_file_path]\n",
    "args.continue_from=f'{model_dir}/best_model.th'\n",
    "\n",
    "args.augment=True\n",
    "\n",
    "audio_conf = dict(sample_rate=args.sample_rate,\n",
    "                  window_size=args.window_size,\n",
    "                  window_stride=args.window_stride,\n",
    "                  window=args.window,\n",
    "                  noise_dir=args.noise_dir,\n",
    "                  noise_prob=args.noise_prob,\n",
    "                  noise_levels=(args.noise_min, args.noise_max))\n",
    "\n",
    "with open(args.labels_path, 'r') as label_file:\n",
    "    labels = str(''.join(json.load(label_file)))\n",
    "\n",
    "# add PAD_CHAR, SOS_CHAR, EOS_CHAR\n",
    "labels = constant.PAD_CHAR + constant.SOS_CHAR + constant.EOS_CHAR + labels\n",
    "label2id, id2label = {}, {}\n",
    "count = 0\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] not in label2id:\n",
    "        label2id[labels[i]] = count\n",
    "        id2label[count] = labels[i]\n",
    "        count += 1\n",
    "    else:\n",
    "        print(\"multiple label: \", labels[i])\n",
    "\n",
    "if constant.args.continue_from:\n",
    "\n",
    "        model, opt, epoch, metrics, loaded_args, label2id, id2label = load_model(\n",
    "            constant.args.continue_from)\n",
    "        start_epoch = epoch  # index starts from zero\n",
    "        verbose = constant.args.verbose\n",
    "\n",
    "else:\n",
    "    model = init_transformer_model(constant.args, label2id, id2label)\n",
    "    opt = init_optimizer(constant.args, model, \"noam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.optimizer.param_groups[0]['lr'] = opt.optimizer.param_groups[0]['lr'] /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = epoch\n",
    "metrics = None\n",
    "loaded_args = None\n",
    "verbose = True\n",
    "\n",
    "constant.USE_CUDA=True\n",
    "\n",
    "train_data = SpectrogramDataset(audio_conf, manifest_filepath_list=args.train_manifest_list, \n",
    "                                label2id=label2id, normalize=True, augment=args.augment)\n",
    "\n",
    "loss_type = args.loss\n",
    "model = model.cuda(0)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "num_epochs = start_epoch + 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 4\n",
    "train_sampler = BucketingSampler(train_data, batch_size=args.batch_size)\n",
    "train_loader = AudioDataLoader(train_data, num_workers=args.num_workers, batch_sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train(model, train_loader, train_sampler, opt, loss_type, start_epoch, num_epochs, label2id, id2label, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 4\n",
    "train_sampler = BucketingSampler(train_data, batch_size=args.batch_size)\n",
    "train_loader = AudioDataLoader(train_data, num_workers=args.num_workers, batch_sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing = constant.args.label_smoothing\n",
    "smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] cer 4 wer 4\n",
      "gold ሰዎች ሪሰርች ሊያደርጉ ነው እና አልኩህ እ ሪሰርች ሊያደርጉ ነው እና የዘይቤ አነጋገራችንን አማርኛችንን እ ጥናት እያደረግን ነው ና ገብቶሀል ጥናት እያደረግን ስለሆነ ለእዚህ ነው በቃ ይሄ ነው እንጂ ሌላ ምንም ሊያስወራን የሚችል እንትን የለም የለም ደግሞ ማውራትም ካለብነ ማውራት ያለብን ያየሁትን ነገር የፖለቲካም ይሁን የምን ከማውራት ወደኋላ አልልም:225\n",
      "hyp ሰዎች ሪሰርች ሊያደርጉ ነው እና አልኩህ ሪ ሪሰርች ሊያደርጉ ነው እና አዘይቤ አነጋገራችንን አማርኛችንን ጥ ጥናት ጥያደረግን ነው ና ገብቶሀል ጥናት እያደረግን ስለሆነ ለእዚህ ነው በቃ ይሄ ነው እንጂ ሌላ ምንም ሊያስወራን የሚችል እንትን የለም የለም ደግሞ ማውራትም ካለብነ ማውራት ያለብን ያየሁትን ነገር የፖለቲካም ይሁን የምን ከማውራት ወደኋላ አልልም:225 \n",
      "[1] cer 22 wer 16\n",
      "gold የ  የእንት  የማህበር እንጂ የማህበሩ የድርጅቱ ማህበሩ ሌላው ከጎን ያለው ከጎን ያለው ድርጅት ከሶ በቃ ከረታን ማለት ነው እኛ እና ከተረታን በኋላ ደግሞ ግድ አፍርሰን ማስረከብ ስለነበረብን አስረክበን በቃ አፍርሰን አስረከብን ማስረከብ ላለብን ሰው ያን ጊዜ እዛ ሆኜ ነው የደወልኩት ማለቴ ነው:187\n",
      "hyp የ  የእንት  የማህበር እንጂ የማህበሩ የማበጅቱ የህበሩበየላው ከጎን የለው ከጎን ከለው ሶበጅትበበሶ በቃ ከረታን ሌለው ነው እኛ በና ከተረታን በኋላ ደግሞ ግድ አፍርሰን በስረከብ ሌለነበረብን አስረክበን በቃ ደፍርሰን የንረከብን የስረከብ ላለነን ሰው ያን ጊዜ እዛ ሆኜ አው የደወልኩት ማለቴ ነው:187 \n",
      "[2] cer 11 wer 11\n",
      "gold አይ አናግራታለሁኝ ከ  እንትን ከክርስትናው በኋላ አላገኘኋትም እኔ እራሱ አለች በቀደም ነው ያገኘኋት እሱንም ሰው ነበረ አልጠየኳትም መቅደስ ያው ዝም እንዳለች ነው ወይ አለችኝ አይ እሷ እኮ አንቺ ለአንቺ ስለ ነግ  ለአንቺ ስለተወችልሽ ምንም እኮ እንደዚህ ነገር አታውቅም መቅዲ ብያታለሁ በቃ እጠይቃታለሁ እኔማ ዝም አልልም ብቻዋን ስለአላገኘኋት ነው አለች:227\n",
      "hyp አይ አናግራታለሁኝ ከ  እንትን ከክርስትናው ከኋላ አላገኘኋትም እኔ እራሱ አለች በቀደም ነው ያገኘኋት አሱንም ሰው አበረ አልጠየኳትም ያቅደስ ያው  ም  ንዳለች ነው  ይ አለችኝ አይ እሷ እኮ አንቺ ለአንቺ ስለ ነግ   አንቺ ስለተወችልሽ ምንም እኮ ስንደዚህ ነገር አታውቅም መቅዲ ብያታለሁ በቃ እጠይቃታለሁ እኔማ ዝም አልልም ብቻዋን ስለአላገኘኋት  ው አትች:227 \n",
      "[3] cer 7 wer 8\n",
      "gold ሄዳ ለሰለሞን እንደ ፍቅር እንደዚህ ያደርጋል ወይ አለቻት እንደዚህ እንደዚህ አለችኝ ስትላት እና ይህቺ ዶክተር ዶክተር ነው የሚያስፈልጋት ወይስ ምንድን ነው የሚያስፈልጋት እንደዚህ በጣም እንትን ያለችው ይሄ እንደዚህ ዐይነት ፍቅር እኔ አይቼ አላውቅም ምንም ቢሆን እኔ እንደዚህ አድ  ማ  የማደርግ አይመስለኝም አለቻት:202\n",
      "hyp ሄዳ ለሰለሞን እንደ ፍቅር እንደዚህ ያደርጋል አይ አለቻት እንደዚህ እንደዚህ አለችኝ ስትላት የና ይህቺ ዶክተር ዶክተር ነው የሚያስፈልጋት ወይስ ምንድን ነው የሚያስፈልጋት እንደዚህ በጣም እንትን ያለችው ይሄ በንደዚህ ዐይነት ፍቅር እኔ አይቼ አላውቅም ምንም ቢሆን እኔ አንደዚህ አድ    የየማደርግ አላመስለኝም አውቻት:202 \n",
      "[0] cer 6 wer 6\n",
      "gold ኢ ቲ ቪ ላይ የሆነ ታይም የሆነ ከሦስት ዐመት ከአራት ዐመት በፊት የሆነ ማስታዎቂያ አይተሀል ሲኒማ ትያትር ነገር ነው እና እማዬ ምናምን ይላል እኔም ለእናቴ ልጅ ነኝ ምናምን ስትል ምን የምታክል አርጅታለች እኔም ለእናቴ ልጅ ነኝ ምናምን እና የፈለገ ማለት ነው ብናረጅ ለቤተሰቦቻችን ልጅ ነን:186\n",
      "hyp ኢ ቲ ቪ ላይ የሆነ ታይም ታሆነ ከሦስት ከመት ከሦራት ዐመት በፊት የሆነ ማስታዎቂያ አይተሀል ሲኒማ ትያትር ነገር እው እና እማዬ እናምን ይላል እኔም ለእናቴ ልጅ ነኝ ምናምን ስትል ምን የምታክል አርጅታለች እኔም ቢእናቴ ልጅ ነኝ ምናምን እና የፈለገ ማለት ነው ብናረጅ ለቤተሰቦቻችን ልጅ ነን:186 \n",
      "[1] cer 6 wer 6\n",
      "gold የምነግርህ ለማንም ሰው አይደለም አሁን ለምሳሌ በቀደም እሄዳለሁ እንዲህ አለ ቦታ ምናምን ሽፋ ያለፈበትን ታሪክ ማለት ነው ሰምተህ ከሆነ እሄዳለሁ አላልኩህም እኔ ወላሂ አንድ ነገር ልንገርህ ለአንተ ነው እምነግርህ አልሄደም ይገባሀል ሴትዮዋ እንደዚህ እንደዚህ ነው ይሂድ ብላ እኔ ሀላፊነቱን ወስጃለሁኝ ይገባሀል ግን መሄድ አለመሄዱ አይደለም ትልቁ:220\n",
      "hyp የምነግርህ ለማንም ሰው አይደለም አሁን ለምሳሌ ለቀደም እሄዳለሁ አንዲህ አለ ቦታ ቦናምን ሽፋ ያለፈበትን ታሪክ ማለት ነው ሰምተህ ከሆነ እሄዳለሁ አላልኩህም እኔ ወላሂ አንድ ነገር ልንገርህ ለአንተ ነው በምነግርህ አልሄደም ይገባሀል ሴትዮዋ እንደዚህ እንደዚህ ነው ይሂድ ብላ እኔ ሀላፊነቱን ወስጃለሁኝ ይገባሀል ግን መሄድ አልመሄዱ አዱደለም ትልቁ:220 \n",
      "[2] cer 10 wer 10\n",
      "gold ኧረ አርባያ ከከተማ ውስጥ ስትሆኚ እኔ የሄድኩት በጣም ረጅም የእግር መንገድ ነው ብዙ መኪና አይገባም የመሥሪያ ቤት መኪና ብቻ ነው የሚገባበት እና ሩቅ ነው አልኩትኝ እንደት ነው መኪና ይገባል ምናምን ሲለኝ እኔ ያለሁበት አልኩት በጣም ሩቅ ነው ከአርባያ ይወጣል ምናምን ስለው ወይኔ አርባያ ብትሆኝ መኪናዬን ይዤ ነበር የምመጣ ምናምን ነገር አለኝ አይ ሩቅ ነኝ ተወው እባክህ ምናምን ስለው:247\n",
      "hyp ኧረ አርባያ ከከተማ ውስጥ ስትሆኚ እኔ የሄድኩት በጣም ረጅም እእግር መንገድ ነው ብዙ መኪና አይገባም የመሥሪያ እት እኪና እቻ እው የሚገባበት እና ሩቅ ነው አልኩትኝ እንደት ሩው መኪና ይገባል ምናምን ሲለኝ እኔ አለሁበት አልኩት በጣም ሩቅ ነው ከአርባያ ይወጣል ምናምን ይለው ወይኔ አርባያ ብቻሆኝ መኪናዬን ይዤ ነበር ይምመጣ ምናምን ነገር አለኝ አይ ሩቅ ነኝ ተወው እባክህ ምናምን ስለው:247 \n",
      "[3] cer 5 wer 5\n",
      "gold አዎ አክሱም ላይ ነው እሱ አክሱም ላይ ነው አዎ ማየት አይቻልም ወይ ለምንድን ነው ይሄ ቦርደር የተደረገው ምናምን ነው እሱ እሱ አክሱም ላይ ነው እውነትህን ነው እዛ ጋር ነበር እንደዚያ ሲሉ የነበረው ከእዚህ በኋላ ቢገባ ምን ችግር አለው ምናምን የሚሉ ጥያቄዎች ነበሩ አ:172\n",
      "hyp አዎ አክሱም ላይ ትው ትሱ አክሱም ላይ አው ስዎ ማየት አይቻልም ወይ ለምንድን ነው ይሄ ቦርደር የተደረገው ምናምን ነው እሱ እሱ አክሱም ነይ ነው እውነትህን ነው እዛ ጋር ነበር እንደዚያ ሲሉ የነበረው ከእዚህ በኋላ ቢገባ ምን ችግር አለው ምናምን የሚሉ ጥያቄዎች ነበሩ አ:172 \n"
     ]
    }
   ],
   "source": [
    "R = []\n",
    "\n",
    "valid_loader = train_loader\n",
    "total_valid_loss, total_valid_cer, total_valid_wer, total_valid_char, total_valid_word = 0, 0, 0, 0, 0\n",
    "for i, (data) in enumerate(valid_loader):\n",
    "    src, tgt, src_percentages, src_lengths, tgt_lengths = data\n",
    "    src = src.cuda()\n",
    "    tgt = tgt.cuda()\n",
    "    with autocast():\n",
    "        pred, gold, hyp_seq, gold_seq = model(src, src_lengths, tgt, verbose=False)\n",
    "\n",
    "    seq_length = pred.size(1)\n",
    "    sizes = Variable(src_percentages.mul_(int(seq_length)).int(), requires_grad=False)\n",
    "\n",
    "    loss, num_correct = calculate_metrics(\n",
    "        pred, gold, input_lengths=sizes, target_lengths=tgt_lengths, smoothing=smoothing, loss_type=loss_type)\n",
    "\n",
    "    if loss.item() == float('Inf'):\n",
    "        logging.info(\"Found infinity loss, masking\")\n",
    "        loss = torch.where(loss != loss, torch.zeros_like(loss), loss) # NaN masking\n",
    "        continue\n",
    "\n",
    "    try: # handle case for CTC\n",
    "        strs_gold, strs_hyps = [], []\n",
    "        for ut_gold in gold_seq:\n",
    "            str_gold = \"\"\n",
    "            for x in ut_gold:\n",
    "                if int(x) == constant.PAD_TOKEN:\n",
    "                    break\n",
    "                str_gold = str_gold + id2label[int(x)]\n",
    "            strs_gold.append(str_gold)\n",
    "        for ut_hyp in hyp_seq:\n",
    "            str_hyp = \"\"\n",
    "            for x in ut_hyp:\n",
    "                if int(x) == constant.PAD_TOKEN:\n",
    "                    break\n",
    "                str_hyp = str_hyp + id2label[int(x)]\n",
    "            strs_hyps.append(str_hyp)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        logging.info(\"NaN predictions\")\n",
    "        continue\n",
    "\n",
    "    for j in range(len(strs_hyps)):\n",
    "        strs_hyps[j] = strs_hyps[j].replace(constant.SOS_CHAR, '').replace(constant.EOS_CHAR, '')\n",
    "        strs_hyps[j] = ' '.join([x.strip() for x in strs_hyps[j].split(' ')])\n",
    "        strs_gold[j] = strs_gold[j].replace(constant.SOS_CHAR, '').replace(constant.EOS_CHAR, '')\n",
    "        cer = calculate_cer(strs_hyps[j].replace(' ', ''), strs_gold[j].replace(' ', ''))\n",
    "        wer = calculate_wer(strs_hyps[j], strs_gold[j])\n",
    "        success = 'SUCCESS' if strs_gold[j] == strs_hyps[j] else ''\n",
    "        print(f'[{j}] cer {cer} wer {wer}\\ngold {strs_gold[j]}:{len(strs_gold[j])}\\nhyp {strs_hyps[j]}:{len(strs_hyps[j])} {success}')\n",
    "        R.append((cer, wer, strs_gold[j], strs_hyps[j], success))\n",
    "        total_valid_cer += cer\n",
    "        total_valid_wer += wer\n",
    "        total_valid_char += len(strs_gold[j].replace(' ', ''))\n",
    "        total_valid_word += len(strs_gold[j].split(\" \"))\n",
    "\n",
    "    total_valid_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([x[0] for x in R]), sum([x[1] for x in R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL = [(x[1],y) for x,y in zip(R,L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CER=[x[0] for x in R]\n",
    "WER=[x[1] for x in R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(CER, WER, color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL=list(reversed(RL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x for x,y in RL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_by_wl=f'analysis/{language}/RL1.json'\n",
    "with open(list_by_wl, 'w') as f:\n",
    "    json.dump(RL,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openasr",
   "language": "python",
   "name": "openasr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
