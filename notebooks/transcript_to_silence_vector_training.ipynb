{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcript to silence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from matplotlib.pylab import *\n",
    "import librosa\n",
    "import torch\n",
    "from epoch_time import epoch_time\n",
    "from tqdm.notebook import tqdm\n",
    "from OpenASR_convert_reference_transcript import txt_to_stm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from padarray import padarray\n",
    "from to_samples import to_samples\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import audioread\n",
    "import random\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage='NIST'\n",
    "sample_rate=8000\n",
    "window = sample_rate\n",
    "H=window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts = list(sorted(glob(f'{stage}/*/build/transcription/*.txt')))\n",
    "len(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files=[x.replace('/transcription/', '/audio/').replace('.txt','.wav') for x in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samples=[]\n",
    "Y_samples=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53504c99850c4cf0bc02e799dcbc296c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for transcript_file in tqdm(transcripts):\n",
    "    audio_file = transcript_file.replace('/transcription/', '/audio/').replace('.txt','.wav')\n",
    "    if not os.path.exists(audio_file):\n",
    "        print('missing', audio_file)\n",
    "        continue\n",
    "    file = \"_\".join(os.path.basename(transcript_file).split(\"_\")[:-1])\n",
    "    channel = os.path.basename(transcript_file).split(\"_\")[-1].split(\".\")[-2]\n",
    "    transcript_df = pd.read_csv(transcript_file, sep = \"\\n\", header = None, names = [\"content\"])\n",
    "    result = txt_to_stm(transcript_df, file, channel)\n",
    "    silences=[(float(x[-2]), float(x[-1])) for x in result if len(x)==5]\n",
    "    x_np,sr=librosa.load(audio_file, sr=sample_rate)\n",
    "    with audioread.audio_open(audio_file) as f:\n",
    "        sr = f.samplerate\n",
    "    if sr != sample_rate:\n",
    "        print('RESIZING', sr, audio_file)\n",
    "        sf.write(audio_file, x_np, sample_rate)\n",
    "    recording_length=x_np.shape[0]\n",
    "    silence_segments=[(int(a*sample_rate), int(b*sample_rate)) for (a,b) in silences]\n",
    "    y_np=np.zeros(recording_length,dtype=x_np.dtype)\n",
    "    for lower, upper in silence_segments:\n",
    "        y_np[lower:upper]=1\n",
    "    pad_length=(x_np.size + (H-(x_np.size % H)))\n",
    "    x_samples_np=to_samples(x_np, window, 600)\n",
    "    y_samples_np=to_samples(y_np, window, 600)\n",
    "    X_samples.extend(x_samples_np)\n",
    "    Y_samples.extend(y_samples_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73194"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73194"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(zip(X_samples, Y_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_samples=[(x,y) for x,y in zip(X_samples, Y_samples)]\n",
    "random.shuffle(XY_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73194"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_samples = [x for x,y in XY_samples]\n",
    "Y_samples = [y for x,y in XY_samples]\n",
    "len(X_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fudge=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.Tensor(X_samples[0:fudge]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_y = torch.Tensor(Y_samples[0:fudge]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = TensorDataset(tensor_x,tensor_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([73194, 8000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 8000, 8000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in,D_out=window,window\n",
    "D_in,H,D_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    "    torch.nn.ReLU()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn='silence_detector.pt'\n",
    "if 1:\n",
    "    model.load_state_dict(torch.load(model_fn))\n",
    "else:\n",
    "    w1_np = np.random.randn(D_in, H)\n",
    "    w2_np = np.random.randn(H, D_out)\n",
    "    w1 = torch.randn((D_in, H), device=device, dtype=dtype)\n",
    "    w2 = torch.randn((H, D_out), device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "learning_rate =.0001\n",
    "criterion = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(device, model, iterator, optimizer, criterion, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(iterator):\n",
    "        x=batch[0]\n",
    "        y=batch[1]\n",
    "        optimizer.zero_grad()\n",
    "        y_pred=model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(device, model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            x=batch[0]\n",
    "            y=batch[1]\n",
    "            y_pred=model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.00002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10000\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 16s Train Loss: 137514.291 Val. Loss: 137327.232\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 02 | Time: 0m 16s Train Loss: 119823.062 Val. Loss: 117262.320\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 03 | Time: 0m 16s Train Loss: 113188.154 Val. Loss: 109194.153\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 04 | Time: 0m 16s Train Loss: 109251.670 Val. Loss: 105593.346\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 05 | Time: 0m 16s Train Loss: 106310.432 Val. Loss: 104586.261\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 06 | Time: 0m 16s Train Loss: 104178.904 Val. Loss: 103161.118\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 07 | Time: 0m 16s Train Loss: 102574.435 Val. Loss: 101129.233\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 08 | Time: 0m 16s Train Loss: 100894.892 Val. Loss: 100034.608\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 09 | Time: 0m 16s Train Loss: 99604.185 Val. Loss: 98198.332\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 10 | Time: 0m 16s Train Loss: 98279.587 Val. Loss: 96855.700\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 11 | Time: 0m 17s Train Loss: 96877.851 Val. Loss: 96398.778\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 12 | Time: 0m 17s Train Loss: 94877.188 Val. Loss: 98625.274\n",
      "Epoch: 13 | Time: 0m 16s Train Loss: 94964.452 Val. Loss: 93038.982\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 14 | Time: 0m 16s Train Loss: 94284.486 Val. Loss: 90929.922\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 15 | Time: 0m 16s Train Loss: 92653.516 Val. Loss: 93074.225\n",
      "Epoch: 16 | Time: 0m 16s Train Loss: 91950.388 Val. Loss: 91571.619\n",
      "Epoch: 17 | Time: 0m 16s Train Loss: 91352.409 Val. Loss: 89970.362\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 18 | Time: 0m 16s Train Loss: 90875.587 Val. Loss: 88311.553\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 19 | Time: 0m 16s Train Loss: 90412.559 Val. Loss: 86436.147\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 20 | Time: 0m 16s Train Loss: 88473.767 Val. Loss: 90672.497\n",
      "Epoch: 21 | Time: 0m 16s Train Loss: 87828.545 Val. Loss: 89994.594\n",
      "Epoch: 22 | Time: 0m 16s Train Loss: 87532.255 Val. Loss: 88089.701\n",
      "Epoch: 23 | Time: 0m 16s Train Loss: 87311.745 Val. Loss: 86128.182\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 24 | Time: 0m 16s Train Loss: 85906.720 Val. Loss: 88725.841\n",
      "Epoch: 25 | Time: 0m 16s Train Loss: 86877.998 Val. Loss: 82263.065\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 26 | Time: 0m 16s Train Loss: 86093.250 Val. Loss: 82923.558\n",
      "Epoch: 27 | Time: 0m 16s Train Loss: 85265.857 Val. Loss: 83814.632\n",
      "Epoch: 28 | Time: 0m 16s Train Loss: 84841.969 Val. Loss: 82960.481\n",
      "Epoch: 29 | Time: 0m 16s Train Loss: 83848.273 Val. Loss: 84677.193\n",
      "Epoch: 30 | Time: 0m 16s Train Loss: 83980.698 Val. Loss: 82527.507\n",
      "Epoch: 31 | Time: 0m 16s Train Loss: 83098.808 Val. Loss: 83556.162\n",
      "Epoch: 32 | Time: 0m 16s Train Loss: 83199.908 Val. Loss: 81052.667\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 33 | Time: 0m 16s Train Loss: 82134.297 Val. Loss: 83205.165\n",
      "Epoch: 34 | Time: 0m 16s Train Loss: 81505.758 Val. Loss: 84273.980\n",
      "Epoch: 35 | Time: 0m 16s Train Loss: 81214.674 Val. Loss: 83337.503\n",
      "Epoch: 36 | Time: 0m 16s Train Loss: 81589.942 Val. Loss: 80121.326\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 37 | Time: 0m 16s Train Loss: 80629.757 Val. Loss: 81883.848\n",
      "Epoch: 38 | Time: 0m 16s Train Loss: 80480.735 Val. Loss: 80945.378\n",
      "Epoch: 39 | Time: 0m 16s Train Loss: 79799.803 Val. Loss: 82138.614\n",
      "Epoch: 40 | Time: 0m 16s Train Loss: 80378.793 Val. Loss: 78324.597\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 41 | Time: 0m 16s Train Loss: 79870.981 Val. Loss: 78460.771\n",
      "Epoch: 42 | Time: 0m 16s Train Loss: 79155.905 Val. Loss: 80003.514\n",
      "Epoch: 43 | Time: 0m 16s Train Loss: 78639.319 Val. Loss: 80269.139\n",
      "Epoch: 44 | Time: 0m 16s Train Loss: 78679.997 Val. Loss: 79001.360\n",
      "Epoch: 45 | Time: 0m 16s Train Loss: 78730.622 Val. Loss: 77461.960\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 46 | Time: 0m 16s Train Loss: 78157.278 Val. Loss: 78872.871\n",
      "Epoch: 47 | Time: 0m 16s Train Loss: 77536.090 Val. Loss: 80156.133\n",
      "Epoch: 48 | Time: 0m 16s Train Loss: 78011.327 Val. Loss: 76691.288\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 49 | Time: 0m 16s Train Loss: 77790.626 Val. Loss: 75822.191\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 50 | Time: 0m 16s Train Loss: 77640.190 Val. Loss: 75449.913\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 51 | Time: 0m 16s Train Loss: 77498.761 Val. Loss: 75086.255\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 52 | Time: 0m 16s Train Loss: 76834.058 Val. Loss: 76043.688\n",
      "Epoch: 53 | Time: 0m 16s Train Loss: 76732.615 Val. Loss: 76034.421\n",
      "Epoch: 54 | Time: 0m 16s Train Loss: 76029.653 Val. Loss: 77518.047\n",
      "Epoch: 55 | Time: 0m 16s Train Loss: 76174.603 Val. Loss: 76068.110\n",
      "Epoch: 56 | Time: 0m 16s Train Loss: 76127.300 Val. Loss: 74974.876\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 57 | Time: 0m 16s Train Loss: 75932.117 Val. Loss: 74986.279\n",
      "Epoch: 58 | Time: 0m 16s Train Loss: 75286.591 Val. Loss: 76360.954\n",
      "Epoch: 59 | Time: 0m 16s Train Loss: 75580.366 Val. Loss: 74209.644\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 60 | Time: 0m 16s Train Loss: 75045.878 Val. Loss: 75665.873\n",
      "Epoch: 61 | Time: 0m 16s Train Loss: 75157.899 Val. Loss: 74092.427\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 62 | Time: 0m 16s Train Loss: 74033.177 Val. Loss: 77828.311\n",
      "Epoch: 63 | Time: 0m 16s Train Loss: 75553.665 Val. Loss: 70920.321\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 64 | Time: 0m 16s Train Loss: 74505.720 Val. Loss: 74192.058\n",
      "Epoch: 65 | Time: 0m 16s Train Loss: 74349.317 Val. Loss: 74062.235\n",
      "Epoch: 66 | Time: 0m 16s Train Loss: 74113.244 Val. Loss: 74288.376\n",
      "Epoch: 67 | Time: 0m 16s Train Loss: 74053.387 Val. Loss: 74065.445\n",
      "Epoch: 68 | Time: 0m 16s Train Loss: 73862.447 Val. Loss: 73747.742\n",
      "Epoch: 69 | Time: 0m 16s Train Loss: 73775.531 Val. Loss: 73255.029\n",
      "Epoch: 70 | Time: 0m 16s Train Loss: 73572.248 Val. Loss: 73693.770\n",
      "Epoch: 71 | Time: 0m 16s Train Loss: 73625.283 Val. Loss: 73157.466\n",
      "Epoch: 72 | Time: 0m 16s Train Loss: 73011.865 Val. Loss: 75279.869\n",
      "Epoch: 73 | Time: 0m 16s Train Loss: 74220.862 Val. Loss: 69352.946\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 74 | Time: 0m 16s Train Loss: 73391.016 Val. Loss: 71753.557\n",
      "Epoch: 75 | Time: 0m 16s Train Loss: 72756.236 Val. Loss: 73321.409\n",
      "Epoch: 76 | Time: 0m 16s Train Loss: 72862.125 Val. Loss: 72616.057\n",
      "Epoch: 77 | Time: 0m 16s Train Loss: 72634.299 Val. Loss: 73334.209\n",
      "Epoch: 78 | Time: 0m 16s Train Loss: 72306.213 Val. Loss: 73397.059\n",
      "Epoch: 79 | Time: 0m 16s Train Loss: 72965.486 Val. Loss: 69972.736\n",
      "Epoch: 80 | Time: 0m 16s Train Loss: 72197.320 Val. Loss: 72980.904\n",
      "Epoch: 81 | Time: 0m 16s Train Loss: 72225.256 Val. Loss: 72129.400\n",
      "Epoch: 82 | Time: 0m 16s Train Loss: 71950.317 Val. Loss: 72532.616\n",
      "Epoch: 83 | Time: 0m 16s Train Loss: 72155.657 Val. Loss: 71190.034\n",
      "Epoch: 84 | Time: 0m 16s Train Loss: 71917.637 Val. Loss: 72036.814\n",
      "Epoch: 85 | Time: 0m 16s Train Loss: 72074.945 Val. Loss: 70498.185\n",
      "Epoch: 86 | Time: 0m 16s Train Loss: 72377.857 Val. Loss: 68904.792\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 87 | Time: 0m 16s Train Loss: 72022.537 Val. Loss: 70044.759\n",
      "Epoch: 88 | Time: 0m 16s Train Loss: 71314.453 Val. Loss: 71660.446\n",
      "Epoch: 89 | Time: 0m 16s Train Loss: 71484.857 Val. Loss: 70859.678\n",
      "Epoch: 90 | Time: 0m 16s Train Loss: 71643.078 Val. Loss: 69734.038\n",
      "Epoch: 91 | Time: 0m 16s Train Loss: 71165.268 Val. Loss: 71255.107\n",
      "Epoch: 92 | Time: 0m 16s Train Loss: 70836.617 Val. Loss: 72326.240\n",
      "Epoch: 93 | Time: 0m 16s Train Loss: 71567.828 Val. Loss: 69169.254\n",
      "Epoch: 94 | Time: 0m 16s Train Loss: 70934.316 Val. Loss: 71190.587\n",
      "Epoch: 95 | Time: 0m 16s Train Loss: 71239.857 Val. Loss: 69278.015\n",
      "Epoch: 96 | Time: 0m 16s Train Loss: 71046.452 Val. Loss: 69704.331\n",
      "Epoch: 97 | Time: 0m 16s Train Loss: 70688.695 Val. Loss: 70788.714\n",
      "Epoch: 98 | Time: 0m 16s Train Loss: 70474.936 Val. Loss: 71491.745\n",
      "Epoch: 99 | Time: 0m 16s Train Loss: 70175.927 Val. Loss: 72654.333\n",
      "Epoch: 100 | Time: 0m 16s Train Loss: 70312.163 Val. Loss: 71153.280\n",
      "Epoch: 101 | Time: 0m 16s Train Loss: 70796.264 Val. Loss: 68590.616\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 102 | Time: 0m 16s Train Loss: 70508.900 Val. Loss: 69528.775\n",
      "Epoch: 103 | Time: 0m 16s Train Loss: 70450.752 Val. Loss: 69713.560\n",
      "Epoch: 104 | Time: 0m 16s Train Loss: 69200.083 Val. Loss: 74016.175\n",
      "Epoch: 105 | Time: 0m 16s Train Loss: 70012.213 Val. Loss: 70010.856\n",
      "Epoch: 106 | Time: 0m 16s Train Loss: 70086.835 Val. Loss: 70158.244\n",
      "Epoch: 107 | Time: 0m 16s Train Loss: 70293.586 Val. Loss: 68906.577\n",
      "Epoch: 108 | Time: 0m 16s Train Loss: 69578.127 Val. Loss: 71165.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109 | Time: 0m 16s Train Loss: 69881.173 Val. Loss: 69816.685\n",
      "Epoch: 110 | Time: 0m 16s Train Loss: 69719.382 Val. Loss: 69618.190\n",
      "Epoch: 111 | Time: 0m 16s Train Loss: 69675.542 Val. Loss: 69907.061\n",
      "Epoch: 112 | Time: 0m 16s Train Loss: 69578.549 Val. Loss: 69754.138\n",
      "Epoch: 113 | Time: 0m 16s Train Loss: 70038.253 Val. Loss: 67813.900\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 114 | Time: 0m 16s Train Loss: 69706.309 Val. Loss: 69123.550\n",
      "Epoch: 115 | Time: 0m 16s Train Loss: 69771.320 Val. Loss: 67792.239\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 116 | Time: 0m 16s Train Loss: 69461.552 Val. Loss: 68979.210\n",
      "Epoch: 117 | Time: 0m 16s Train Loss: 69460.363 Val. Loss: 69230.619\n",
      "Epoch: 118 | Time: 0m 16s Train Loss: 68788.706 Val. Loss: 71498.116\n",
      "Epoch: 119 | Time: 0m 16s Train Loss: 68773.596 Val. Loss: 71296.506\n",
      "Epoch: 120 | Time: 0m 16s Train Loss: 69269.708 Val. Loss: 69082.192\n",
      "Epoch: 121 | Time: 0m 16s Train Loss: 69202.962 Val. Loss: 69109.997\n",
      "Epoch: 122 | Time: 0m 16s Train Loss: 69602.699 Val. Loss: 67179.360\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 123 | Time: 0m 16s Train Loss: 68946.302 Val. Loss: 69012.119\n",
      "Epoch: 124 | Time: 0m 16s Train Loss: 69237.824 Val. Loss: 67858.778\n",
      "Epoch: 125 | Time: 0m 16s Train Loss: 69408.739 Val. Loss: 67051.025\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 126 | Time: 0m 16s Train Loss: 68409.472 Val. Loss: 70587.225\n",
      "Epoch: 127 | Time: 0m 16s Train Loss: 68715.825 Val. Loss: 70165.147\n",
      "Epoch: 128 | Time: 0m 16s Train Loss: 69029.438 Val. Loss: 68058.860\n",
      "Epoch: 129 | Time: 0m 16s Train Loss: 68312.294 Val. Loss: 70205.115\n",
      "Epoch: 130 | Time: 0m 16s Train Loss: 68419.791 Val. Loss: 69985.963\n",
      "Epoch: 131 | Time: 0m 16s Train Loss: 68801.030 Val. Loss: 68435.090\n",
      "Epoch: 132 | Time: 0m 16s Train Loss: 69165.485 Val. Loss: 66163.468\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 133 | Time: 0m 16s Train Loss: 69234.606 Val. Loss: 65556.912\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 134 | Time: 0m 16s Train Loss: 68374.286 Val. Loss: 68759.822\n",
      "Epoch: 135 | Time: 0m 16s Train Loss: 68121.538 Val. Loss: 70100.655\n",
      "Epoch: 136 | Time: 0m 16s Train Loss: 68246.732 Val. Loss: 69506.574\n",
      "Epoch: 137 | Time: 0m 16s Train Loss: 68704.410 Val. Loss: 67546.119\n",
      "Epoch: 138 | Time: 0m 16s Train Loss: 68216.541 Val. Loss: 69286.618\n",
      "Epoch: 139 | Time: 0m 16s Train Loss: 68627.822 Val. Loss: 67415.840\n",
      "Epoch: 140 | Time: 0m 16s Train Loss: 68023.551 Val. Loss: 68190.720\n",
      "Epoch: 141 | Time: 0m 16s Train Loss: 68041.840 Val. Loss: 69268.213\n",
      "Epoch: 142 | Time: 0m 16s Train Loss: 67920.921 Val. Loss: 69588.990\n",
      "Epoch: 143 | Time: 0m 16s Train Loss: 68737.143 Val. Loss: 66510.952\n",
      "Epoch: 144 | Time: 0m 16s Train Loss: 68446.007 Val. Loss: 67001.011\n",
      "Epoch: 145 | Time: 0m 16s Train Loss: 68571.021 Val. Loss: 66495.021\n",
      "Epoch: 146 | Time: 0m 16s Train Loss: 68147.427 Val. Loss: 67384.360\n",
      "Epoch: 147 | Time: 0m 16s Train Loss: 68165.130 Val. Loss: 67477.217\n",
      "Epoch: 148 | Time: 0m 16s Train Loss: 67728.335 Val. Loss: 69474.533\n",
      "Epoch: 149 | Time: 0m 16s Train Loss: 67713.195 Val. Loss: 69091.282\n",
      "Epoch: 150 | Time: 0m 16s Train Loss: 68611.643 Val. Loss: 65568.589\n",
      "Epoch: 151 | Time: 0m 16s Train Loss: 67582.146 Val. Loss: 69209.889\n",
      "Epoch: 152 | Time: 0m 16s Train Loss: 68596.938 Val. Loss: 65396.274\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 153 | Time: 0m 16s Train Loss: 67669.617 Val. Loss: 68076.348\n",
      "Epoch: 154 | Time: 0m 16s Train Loss: 67563.713 Val. Loss: 68457.567\n",
      "Epoch: 155 | Time: 0m 16s Train Loss: 67767.715 Val. Loss: 67032.502\n",
      "Epoch: 156 | Time: 0m 16s Train Loss: 67597.253 Val. Loss: 68262.211\n",
      "Epoch: 157 | Time: 0m 16s Train Loss: 67968.774 Val. Loss: 66118.434\n",
      "Epoch: 158 | Time: 0m 16s Train Loss: 67137.441 Val. Loss: 69677.829\n",
      "Epoch: 159 | Time: 0m 16s Train Loss: 67538.831 Val. Loss: 67148.159\n",
      "Epoch: 160 | Time: 0m 16s Train Loss: 67915.308 Val. Loss: 65672.643\n",
      "Epoch: 161 | Time: 0m 16s Train Loss: 67792.875 Val. Loss: 66428.170\n",
      "Epoch: 162 | Time: 0m 16s Train Loss: 68305.770 Val. Loss: 63569.896\n",
      "saved silence_detector.pt\n",
      "\n",
      "Epoch: 163 | Time: 0m 16s Train Loss: 66782.160 Val. Loss: 68900.721\n",
      "Epoch: 164 | Time: 0m 16s Train Loss: 67721.467 Val. Loss: 65617.068\n",
      "Epoch: 165 | Time: 0m 16s Train Loss: 67250.968 Val. Loss: 68240.972\n",
      "Epoch: 166 | Time: 0m 16s Train Loss: 68026.261 Val. Loss: 64694.013\n",
      "Epoch: 167 | Time: 0m 16s Train Loss: 67189.452 Val. Loss: 67178.910\n",
      "Epoch: 168 | Time: 0m 16s Train Loss: 67587.577 Val. Loss: 65771.423\n",
      "Epoch: 169 | Time: 0m 16s Train Loss: 67349.809 Val. Loss: 66786.782\n",
      "Epoch: 170 | Time: 0m 16s Train Loss: 67090.553 Val. Loss: 67315.135\n",
      "Epoch: 171 | Time: 0m 16s Train Loss: 67219.185 Val. Loss: 66089.803\n",
      "Epoch: 172 | Time: 0m 16s Train Loss: 67403.739 Val. Loss: 66649.284\n",
      "Epoch: 173 | Time: 0m 16s Train Loss: 67286.903 Val. Loss: 66627.224\n",
      "Epoch: 174 | Time: 0m 16s Train Loss: 67200.071 Val. Loss: 66177.107\n",
      "Epoch: 175 | Time: 0m 16s Train Loss: 67249.816 Val. Loss: 65958.767\n",
      "Epoch: 176 | Time: 0m 16s Train Loss: 66603.858 Val. Loss: 68455.485\n",
      "Epoch: 177 | Time: 0m 16s Train Loss: 67349.596 Val. Loss: 65327.879\n",
      "Epoch: 178 | Time: 0m 16s Train Loss: 67840.135 Val. Loss: 64119.635\n",
      "Epoch: 179 | Time: 0m 16s Train Loss: 66880.887 Val. Loss: 66835.718\n",
      "Epoch: 180 | Time: 0m 16s Train Loss: 66352.908 Val. Loss: 69004.420\n",
      "Epoch: 181 | Time: 0m 16s Train Loss: 67491.313 Val. Loss: 64844.849\n",
      "Epoch: 182 | Time: 0m 16s Train Loss: 66758.803 Val. Loss: 66778.244\n",
      "Epoch: 183 | Time: 0m 16s Train Loss: 67479.900 Val. Loss: 63951.347\n",
      "Epoch: 184 | Time: 0m 16s Train Loss: 65935.339 Val. Loss: 69744.910\n",
      "Epoch: 185 | Time: 0m 16s Train Loss: 66874.841 Val. Loss: 66076.795\n",
      "Epoch: 186 | Time: 0m 16s Train Loss: 66362.610 Val. Loss: 68311.134\n",
      "Epoch: 187 | Time: 0m 16s Train Loss: 66798.555 Val. Loss: 66120.244\n",
      "Epoch: 188 | Time: 0m 16s Train Loss: 66112.461 Val. Loss: 68290.466\n",
      "Epoch: 189 | Time: 0m 16s Train Loss: 66660.736 Val. Loss: 66535.675\n",
      "Epoch: 190 | Time: 0m 16s Train Loss: 66351.726 Val. Loss: 66888.609\n",
      "Epoch: 191 | Time: 0m 16s Train Loss: 66501.012 Val. Loss: 66935.100\n",
      "Epoch: 192 | Time: 0m 16s Train Loss: 66112.921 Val. Loss: 68517.935\n",
      "Epoch: 193 | Time: 0m 16s Train Loss: 66259.520 Val. Loss: 67421.934\n",
      "Epoch: 194 | Time: 0m 16s Train Loss: 66481.506 Val. Loss: 66163.044\n",
      "Epoch: 195 | Time: 0m 16s Train Loss: 66809.140 Val. Loss: 65335.967\n",
      "Epoch: 196 | Time: 0m 16s Train Loss: 66834.214 Val. Loss: 64285.375\n",
      "Epoch: 197 | Time: 0m 16s Train Loss: 66606.785 Val. Loss: 65465.437\n",
      "Epoch: 198 | Time: 0m 16s Train Loss: 66016.935 Val. Loss: 67546.755\n",
      "Epoch: 199 | Time: 0m 16s Train Loss: 66542.107 Val. Loss: 64996.808\n",
      "Epoch: 200 | Time: 0m 16s Train Loss: 66801.098 Val. Loss: 65091.071\n",
      "Epoch: 201 | Time: 0m 16s Train Loss: 66910.773 Val. Loss: 63711.982\n",
      "Epoch: 202 | Time: 0m 16s Train Loss: 66182.318 Val. Loss: 66625.991\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4b2e822aa11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0merror_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-902d0e26b709>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(device, model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "error_nn=[]\n",
    "n_passes_not_saved = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_iterator = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                 batch_size=128, shuffle=False, num_workers=0)\n",
    "    valid_iterator = torch.utils.data.DataLoader(test_dataset,\n",
    "                                                 batch_size=128, shuffle=False, num_workers=0)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = trainer(device, model, train_iterator, optimizer, criterion)\n",
    "    valid_loss = evaluator(device, model, valid_iterator, criterion)\n",
    "    error_nn.append(train_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s Train Loss: {train_loss:.3f} Val. Loss: {valid_loss:.3f}')\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_fn)\n",
    "        print('saved', model_fn)\n",
    "        print()\n",
    "        n_passes_not_saved = 0\n",
    "    else:\n",
    "        n_passes_not_saved += 1\n",
    "    \n",
    "    if n_passes_not_saved > 50:\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] *= 0.998\n",
    "        print(f\"learning rate is now {g['lr']:.8f}\")\n",
    "        n_passes_not_saved = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf14362a30>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD5CAYAAAA5v3LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcnOwlbNiAQIOy7KEQWt1qtQtWKrVqxi7Tllmrtrba3t9Xb/mpv7ea1V3ttq62tVLR14Vp7wSoiohWrqAREZN+XQIAAIQmQPZ/fH3OCk5AFQpIJ5P18POaRM5853zOfOQzzme/3e84Zc3dEREQaEhXpBEREpH1ToRARkUapUIiISKNUKEREpFEqFCIi0igVChERaVRMUyuY2WzgGmC/u4+u89h3gPuBdHc/EMTuBmYCVcA33X1hEB8PPA50Al4C7nB3N7N44AlgPHAQuMndtwdtZgA/CJ7uJ+4+p6l809LSPCsrq6nVREQkzPLlyw+4e3p9jzVZKAh9uP+G0If5cWbWF7gC2BkWGwlMB0YBvYFXzWyou1cBjwCzgHcIFYqpwAJCRaXA3Qeb2XTgPuAmM0sB7gGyAQeWm9l8dy9oLNmsrCxycnJO4mWJiEgNM9vR0GNNDj25+xLgUD0PPQh8l9CHeI1pwDPuXubu24DNwAQzywC6uvtSD53h9wRwXVibmp7Cc8DlZmbAFGCRux8KisMiQsVFRETaULPmKMzsWmC3u39Q56E+wK6w+7lBrE+wXDdeq427VwKFQGoj26ovn1lmlmNmOfn5+c15SSIi0oBTLhRmlgh8H/hhfQ/XE/NG4s1tUzvo/qi7Z7t7dnp6vUNsIiLSTM3pUQwCBgAfmNl2IBNYYWa9CH3r7xu2biawJ4hn1hMnvI2ZxQDdCA11NbQtERFpQ6dcKNz9Q3fv4e5Z7p5F6AN9nLvvBeYD080s3swGAEOA99w9Dyg2s0nB/MMtwLxgk/OBGcHyDcBrwTzGQuBKM0s2s2TgyiAmIiJt6GQOj30auBRIM7Nc4B53f6y+dd19jZnNBdYClcDtwRFPALfx0eGxC4IbwGPAk2a2mVBPYnqwrUNmdi+wLFjvx+5e36S6iIi0IjvbLjOenZ3tOjxWROTUmNlyd8+u7zGdmR04UlbJA4s2snLX4UinIiLSrqhQBMorq3lo8SZW7mz0fD4RkQ5HhSIQHxPaFWWV1RHORESkfVGhCKhQiIjUT4UiEBMdRXSUUa5CISJSiwpFmPiYKMoqq5peUUSkA1GhCBMqFOpRiIiEU6EIEx8TTVmFCoWISDgVijDxsRp6EhGpS4UijIaeREROpEIRJj4mWoVCRKQOFYowOupJROREKhRh4mOjNJktIlKHCkUYDT2JiJxIhSJMXLSGnkRE6lKhCBM6PFY9ChGRcCoUYeJjNEchIlKXCkWY+JhoyqtUKEREwqlQhAn1KDRHISISrslCYWazzWy/ma0Oi91rZqvMbKWZvWJmvcMeu9vMNpvZBjObEhYfb2YfBo89ZGYWxOPN7Nkg/q6ZZYW1mWFmm4LbjJZ60Q3RHIWIyIlOpkfxODC1Tux+dz/H3c8F/g78EMDMRgLTgVFBm4fNLDpo8wgwCxgS3Gq2ORMocPfBwIPAfcG2UoB7gInABOAeM0tuxms8afEx0VRWO5UafhIROa7JQuHuS4BDdWJFYXeTAA+WpwHPuHuZu28DNgMTzCwD6OruS93dgSeA68LazAmWnwMuD3obU4BF7n7I3QuARZxYsFpUza/caZ5CROQjMc1taGY/BW4BCoGPB+E+wDthq+UGsYpguW68ps0uAHevNLNCIDU8Xk+burnMItRboV+/fs19SR/9HGpFNYlxzd6MiMhZpdmT2e7+fXfvC/wF+EYQtvpWbSTe3DZ1c3nU3bPdPTs9Pb3xxBsRHxsaJdM8hYjIR1riqKengOuD5Vygb9hjmcCeIJ5ZT7xWGzOLAboRGupqaFut5niPQmdni4gc16xCYWZDwu5eC6wPlucD04MjmQYQmrR+z93zgGIzmxTMP9wCzAtrU3NE0w3Aa8E8xkLgSjNLDiaxrwxirSY+Rj0KEZG6mpyjMLOngUuBNDPLJXQk0lVmNgyoBnYAtwK4+xozmwusBSqB29295uv5bYSOoOoELAhuAI8BT5rZZkI9ienBtg6Z2b3AsmC9H7t7rUn1lhY+RyEiIiFNFgp3v7me8GONrP9T4Kf1xHOA0fXES4EbG9jWbGB2Uzm2lPhYDT2JiNSlM7PDaOhJROREKhRhNJktInIiFYowx4eeNEchInKcCkWYuGidmS0iUpcKRZjjJ9ypRyEicpwKRRjNUYiInEiFIsxHhUI9ChGRGioUYXR4rIjIiVQowsRGG2boV+5ERMKoUIQxs9DPoapHISJynApFHfEx0SoUIiJhVCjqCPUoNPQkIlJDhaKO+NgonUchIhJGhaIODT2JiNSmQlGHhp5ERGpToahDRz2JiNSmQlGHhp5ERGpToagjPlY9ChGRcE0WCjObbWb7zWx1WOx+M1tvZqvM7G9m1j3ssbvNbLOZbTCzKWHx8Wb2YfDYQ2ZmQTzezJ4N4u+aWVZYmxlmtim4zWipF92Y+JgonZktIhLmZHoUjwNT68QWAaPd/RxgI3A3gJmNBKYDo4I2D5tZdNDmEWAWMCS41WxzJlDg7oOBB4H7gm2lAPcAE4EJwD1mlnzqL/HUxMdEU64ehYjIcU0WCndfAhyqE3vF3SuDu+8AmcHyNOAZdy9z923AZmCCmWUAXd19qbs78ARwXVibOcHyc8DlQW9jCrDI3Q+5ewGh4lS3YLW4OE1mi4jU0hJzFF8BFgTLfYBdYY/lBrE+wXLdeK02QfEpBFIb2Var0uGxIiK1nVahMLPvA5XAX2pC9azmjcSb26ZuHrPMLMfMcvLz8xtPugmd42MoLq0k1PEREZFmF4pgcvka4PP+0adqLtA3bLVMYE8Qz6wnXquNmcUA3QgNdTW0rRO4+6Punu3u2enp6c19SQCkJMVRVlnNsXL1KkREoJmFwsymAt8DrnX3Y2EPzQemB0cyDSA0af2eu+cBxWY2KZh/uAWYF9am5oimG4DXgsKzELjSzJKDSewrg1irSkmKA+DgkfLWfioRkTNCTFMrmNnTwKVAmpnlEjoS6W4gHlgUHOX6jrvf6u5rzGwusJbQkNTt7l7z1fw2QkdQdSI0p1Ezr/EY8KSZbSbUk5gO4O6HzOxeYFmw3o/dvdakemtI7RwUiqNl9EtNbO2nExFp95osFO5+cz3hxxpZ/6fAT+uJ5wCj64mXAjc2sK3ZwOymcmxJKUnxABw6qh6FiAjozOwTpNYMPalQiIgAKhQnqJmjUI9CRCREhaKOxLhoEmKjVChERAIqFHWYGalJ8Rw4UhbpVERE2gUVinqkJMWpRyEiElChqIcKhYjIR1Qo6pGaFKcT7kREAioU9VCPQkTkIyoU9UjpHEdJRRXHyiubXllE5CynQlGPVF3vSUTkOBWKeqTqMh4iIsepUNQjpbPOzhYRqaFCUQ9d70lE5CMqFPVI6xwaetpfXBrhTEREIk+Foh5J8TGkJsWx69CxplcWETnLqVA0oF9qItsPqFCIiKhQNCArNYkdB49GOg0RkYhToWhA/9RE8opKKa2oanplEZGzmApFA/qnJuIOuQUafhKRjq3JQmFms81sv5mtDovdaGZrzKzazLLrrH+3mW02sw1mNiUsPt7MPgwee8jMLIjHm9mzQfxdM8sKazPDzDYFtxkt8YJPVv/UJADNU4hIh3cyPYrHgal1YquBzwBLwoNmNhKYDowK2jxsZtHBw48As4Ahwa1mmzOBAncfDDwI3BdsKwW4B5gITADuMbPkU3htpyUrKBQ7dOSTiHRwTRYKd18CHKoTW+fuG+pZfRrwjLuXufs2YDMwwcwygK7uvtTdHXgCuC6szZxg+Tng8qC3MQVY5O6H3L0AWMSJBavVJCfG0iU+RhPaItLhtfQcRR9gV9j93CDWJ1iuG6/Vxt0rgUIgtZFtncDMZplZjpnl5Ofnt8DLCP0kav+0RLYfVI9CRDq2li4UVk/MG4k3t03toPuj7p7t7tnp6eknlejJ6K9DZEVEWrxQ5AJ9w+5nAnuCeGY98VptzCwG6EZoqKuhbbWZAalJ5BaU6BBZEenQWrpQzAemB0cyDSA0af2eu+cBxWY2KZh/uAWYF9am5oimG4DXgnmMhcCVZpYcTGJfGcTazIiMrlRVO5v2HWnLpxURaVdimlrBzJ4GLgXSzCyX0JFIh4BfA+nAi2a20t2nuPsaM5sLrAUqgdvdvebr+G2EjqDqBCwIbgCPAU+a2eZgu9MB3P2Qmd0LLAvW+7G715pUb20je3cFYG1eIWMyu7XlU4uItBtNFgp3v7mBh/7WwPo/BX5aTzwHGF1PvBS4sYFtzQZmN5Vja+mfkkhiXDTr8oojlYKISMTpzOxGREUZIzK6snZPUaRTERGJGBWKJozI6MK6vCJC0yYiIh2PCkUTRmZ0o7isktyCkkinIiISESoUTaiZ0F6j4ScR6aBUKJowrGcXoqOMVbmHI52KiEhEqFA0oVNcNGMzu7F068FIpyIiEhEqFCfhgkFprMotpLi0ItKpiIi0ORWKk3DBoFSqqp1l29v0fD8RkXZBheIkjOufTFxMFG9v1vCTiHQ8KhQnISE2mvH9knl7iwqFiHQ8KhQn6aIhaazNK2JvYWmkUxERaVMqFCdpyqheACxYnRfhTERE2pYKxUka3KMzw3t14cVVKhQi0rGoUJyCq8ZkkLOjQMNPItKhqFCcgqvGZAAafhKRjkWF4hRo+ElEOiIVilN0tYafRKSDUaE4RVedo+EnEelYVChO0aB0DT+JSMfSZKEws9lmtt/MVofFUsxskZltCv4mhz12t5ltNrMNZjYlLD7ezD4MHnvIzCyIx5vZs0H8XTPLCmszI3iOTWY2o6Ve9On61Nje5OwoYPuBo5FORUSk1Z1Mj+JxYGqd2F3AYncfAiwO7mNmI4HpwKigzcNmFh20eQSYBQwJbjXbnAkUuPtg4EHgvmBbKcA9wERgAnBPeEGKpBvHZxITZfz5nR2RTkVEpNU1WSjcfQlQ97Kp04A5wfIc4Lqw+DPuXubu24DNwAQzywC6uvtSD/349BN12tRs6zng8qC3MQVY5O6H3L0AWMSJBSsienRNYOroXszN2UVJeVWk0xERaVXNnaPo6e55AMHfHkG8D7ArbL3cINYnWK4br9XG3SuBQiC1kW2dwMxmmVmOmeXk5+c38yWdmhkXZFFUWsm8lbvb5PlERCKlpSezrZ6YNxJvbpvaQfdH3T3b3bPT09NPKtHTld0/meG9ujBn6Q5CnSQRkbNTcwvFvmA4ieDv/iCeC/QNWy8T2BPEM+uJ12pjZjFAN0JDXQ1tq10wM26ZnMW6vCKW7yiIdDoiIq2muYViPlBzFNIMYF5YfHpwJNMAQpPW7wXDU8VmNimYf7ilTpuabd0AvBbMYywErjSz5GAS+8og1m5cd15vuiTE8MRSTWqLyNnrZA6PfRpYCgwzs1wzmwn8ArjCzDYBVwT3cfc1wFxgLfAycLu718z23gb8kdAE9xZgQRB/DEg1s83AtwmOoHL3Q8C9wLLg9uMg1m4kxsVw4/i+vPRhHvnFZZFOR0SkVdjZNr6enZ3tOTk5bfZ8m/cX84kHlvAfVw1n1iWD2ux5RURakpktd/fs+h7TmdmnaXCPLmT3T+aZZbs0qS0iZyUVihZw0/l92Zp/lBxNaovIWUiFogVcfU4GSXHRPL9C51SIyNlHhaIFJMbFcMHgNJZszNfwk4icdVQoWsglQ9PZfbiE7QePRToVEZEWpULRQi4ZkgbAm5va5hIiIiJtRYWihfRPTaJfSiJLNh6IdCoiIi1KhaIFXTwkjX9s2M+YHy3kJ39fq/kKETkrxEQ6gbPJ5yb2Y39xGRVV1fzxn9vISkviC5P6RzotEZHToh5FCxrVuxt/uCWbx2acz8eHpfOj+WvYW1ga6bRERE6LCkUriI4yfnDNSCqrnRc/1G9ri8iZTYWilQxK78yIjK68uKrdXBldRKRZVCha0TXnZLBi52F2Hy6JdCoiIs2mQtGKrh6TAcALH6hXISJnLhWKVpSVlsTkgan8evEmNu8vjnQ6IiLNokLRyh64aSwJsdHc+ucVFJZURDodEZFTpkLRyjK6deI3nxvHjoNH+eqcHEorqppuJCLSjqhQtIHJg1J54LPnsmzHIWbOWUZRqXoWInLmOK1CYWZ3mNlqM1tjZncGsRQzW2Rmm4K/yWHr321mm81sg5lNCYuPN7MPg8ceMjML4vFm9mwQf9fMsk4n30j61Nje/PKGsby79RDXP/w2uw7pKrMicmZodqEws9HAV4EJwFjgGjMbAtwFLHb3IcDi4D5mNhKYDowCpgIPm1l0sLlHgFnAkOA2NYjPBArcfTDwIHBfc/NtD64fn8kTMyewr6iUTz/8Fh/mFkY6JRGRJp1Oj2IE8I67H3P3SuAN4NPANGBOsM4c4LpgeRrwjLuXufs2YDMwwcwygK7uvtRDV9F7ok6bmm09B1xe09s4U10wKI3nv34h0VHGvS+ujXQ6IiJNOp1CsRq4xMxSzSwRuAroC/R09zyA4G+PYP0+wK6w9rlBrE+wXDdeq01QjAqB1LqJmNksM8sxs5z8/Pb/exCDe3Tm+nGZrNhRoPkKEWn3ml0o3H0doaGgRcDLwAdAZSNN6usJeCPxxtrUzeVRd8929+z09PRG824vLh3Wg8pq5+3N+v0KEWnfTmsy290fc/dx7n4JcAjYBOwLhpMI/u4PVs8l1OOokQnsCeKZ9cRrtTGzGKBb8DxnvPP6dadLfAxvbGz/PSAR6dhO96inHsHffsBngKeB+cCMYJUZwLxgeT4wPTiSaQChSev3guGpYjObFMw/3FKnTc22bgBe87Pk14Bio6O4cHAa/9iQrx84EpF27XTPo/irma0FXgBud/cC4BfAFWa2CbgiuI+7rwHmAmsJDVXd7u41Z5/dBvyR0AT3FmBBEH8MSDWzzcC3CY6gOltcOiydvMJSXl23v+mVRUQixM62b7PZ2dmek5MT6TROSkl5FTf87m22HzjK3FsnM6p3t0inJCIdlJktd/fs+h7TmdkR1CkumsdmnE+XhFiu++1b/Gj+Gp2IJyLtjgpFhPXqlsC8b1zIDeMzefKdHVxy/+s88MqGSKclInKcCkU70LNrAj//zDn883sf5/LhPfn9kq0UHqvg76v28H/v7450eiLSwcVEOgH5SEa3Ttz5iSG8um4fv/3HZh5/ezuVVdX0T03kvH7JTW9ARKQVqEfRzozu041Rvbvy6JKtRFmot/Fvcz+gpFyXJxeRyFChaIemnx86L3HWJYP47xvHsvXAUe5fqHkLEYkMDT21Qzdm98WBz2b3JSE2mi9dkMXst7ZxxcieTB50wqWuRERalXoU7VBCbDS3TM4iITZ0FfbvTR3OgLQkvvZkDq+t3xfh7ESko1GhOAN0iovmia9MIDM5ka88nsPrG3Qmt4i0HRWKM0TflESe//oFDExL4id/X0tlVXWkUxKRDkKF4gySEBvNd6cOZ0v+Ue56/kO+99wqcgt0JreItC5NZp9hpozqyYQBKTy3PBcz2FNYwhNfmcAZ/sN/ItKOqVCcYcyMP33pfIpLK3l5dR4/emEtDyzaSFJ8DNPP70v3xLhIpygiZxkVijNQUnwMSfExfHFyFn97fze/fm0zALkFx/jJdWMinJ2InG00R3EGi44y5nxlAi984yKmn9+XZ5ft0tVnRaTFqVCc4bonxjEmsxt3fmIoZsaDr26MdEoicpZRoThL9OqWwMyLBvD8it089e7O4/Hq6rPrh6lEpO1pjuIs8m9XDGV9XhH/b95qDh0to1NcDA+8soH/d81Ipk/oF+n0ROQMpR7FWSQmOorffG4clw/vwS9f2ci9f1+LmfGLl9dz+Fh5pNMTkTPUaRUKM/uWma0xs9Vm9rSZJZhZipktMrNNwd/ksPXvNrPNZrbBzKaExceb2YfBYw9ZcFKAmcWb2bNB/F0zyzqdfDuCpPgYHr0lm7/edgGPfH4c/3vrZIpKKrj37+vILy6LdHoicgZqdqEwsz7AN4Fsdx8NRAPTgbuAxe4+BFgc3MfMRgaPjwKmAg+bWXSwuUeAWcCQ4DY1iM8ECtx9MPAgcF9z8+1oxvdP5pNjMhiR0ZUvXTCAv67I5fyfvsof39zKsfJKfvB/H/IPXTNKRE7C6Q49xQCdzCwGSAT2ANOAOcHjc4DrguVpwDPuXubu24DNwAQzywC6uvtSd3fgiTptarb1HHB5TW9DTt7/u2YEL3zjIj4xoic/e2kdN/5uKX9+Zyf/MidHP7UqIk1qdqFw993AL4GdQB5Q6O6vAD3dPS9YJw/oETTpA+wK20RuEOsTLNeN12rj7pVAIXDCDzKY2SwzyzGznPz8/Oa+pLOWmTEmsxsP3XwuQ3t2Yc2eIu6dNorzs1L49tyVLN1yMNIpikg7djpDT8mEvvEPAHoDSWb2hcaa1BPzRuKNtakdcH/U3bPdPTs9Pb3xxDuwxLgYnvrqJP562wV8cXIWf5iRzYC0JP716ffZV1Qa6fREpJ06naGnTwDb3D3f3SuA54ELgH3BcBLB35qB8Fygb1j7TEJDVbnBct14rTbB8FY34NBp5NzhpSTFMb5/6PiCzvExPPKF8Rwtq+Rzf3iHvMISyiqryCssoeCojpISkZDTKRQ7gUlmlhjMG1wOrAPmAzOCdWYA84Ll+cD04EimAYQmrd8LhqeKzWxSsJ1b6rSp2dYNwGvBPIa0kKE9u/D4l89nX1EZF9/3OsN+8DKTf/4aE3+2mH9uOhDp9ESkHWj2CXfu/q6ZPQesACqB94FHgc7AXDObSaiY3Bisv8bM5gJrg/Vvd/eqYHO3AY8DnYAFwQ3gMeBJM9tMqCcxvbn5SsMmDkxl7tcm87f3c+maEEtK5zieXLqDWU/m8PRXJzG2b3cOHS2nU2w0neKim96giJxV7Gz7gp6dne05OTmRTuOMt7+olOt/9zZHSiv59pXD+MVL64iKMqad25uPD+vBxIGpdI7Xif0iZwszW+7u2fU+pkIhDdl+4Cg3/G4pB46UMTKjK0N7dmbB6r2UVVYTE2VMGpjKr6afS1rn+EinKiKnSYVCmm3D3mJe+GAPt106iKT4GEorqlixo4A3Nx9g9j+3MTazO3/+l4nExehqMCJnMhUKaRXzVu7mjmdW0j81kUkDUvnBNSPokhAb6bREpBkaKxQaZJZmm3ZuHyqrnAWr83huRS5FpRU8/PlxHDxaTpeEGOJjNPEtcjZQj0JaxKNLtvCzl9aTnBhLwbEKAIb06MxnxmUy86IBGpoSaefUo5BW99WLB7KvqIy9haWc1687x8qreHNTPve9vJ5tB47w71OGs3jdPqad26fWIbbuzusb9nPxkHRio1VMRNoj9SikVT3wygYeem0zcdFRlFdVM3FACj//zBjyi8uYMCCF19bvZ+acHP59yjBu//jgSKcr0mGpRyER860rhlJYUsHhkgrOyezOz15ax2X//QYA/3XDObyxMXQRx9+/sYUvTOxPt0RNhou0N+pRSJtatv0Q6/KKeOa9XRSVVpBfXEZ2VjJvbznI9eMyuePyIfRNSYx0miIdjnoU0m6cn5XC+Vkp9OyawNeeXA7Ad64cxv8uz+Wpd3fy3PJcJg9M5dpze9M3OZHx/ZMbvGxIZVU19y/cwKfG9mZ0n25t+TJEOhQVComIK0b0ZHivLpRXVXNu3+6c27c7My8awMI1e/nLOzu5+/kPAUiMi+bCwWkM69mFy0b04Ly+3SmrrCYhNpoFq/fy+yVbWbB6Ly/feTGJcXo7i7QGDT1JxOwvLqWyyundvVOteFW1s7ughG0Hj/Ly6jze3XaIHQePUVXtxEYbldXONy8bwmvr95NXWMKBI+V86YIsfnTtqAi9EpEzn4aepF3q0SWh3nh0lNEvNZF+qYl8bGjoh6iKSyt46cM8tuQfZfuBo/zP4k0A/OzTY9iwt4jH397OuX27c915fU7YXl5hCWmd43X4rUgzqVDIGaFLQiw3nd8PCM1NfP0vK1ibV8RnxvXBrA/r9xbz3edW8ZvXN1NSXsX14zOZMbk/2w8e5eZH3+WSoWn84ZZs9JPrIqdOQ09yRnJ3yquqj18mpPBYBd/76yoqq0PxNzfl0yU+hugoo6LKOVJWyV2fHM7FQ9IYmNa53gnypVsOsnTrQT43oR+9utXf2xE5W+migNLhbNxXzH++sIa1e4r431snc+/f1x0/ZyOtcxyXDuvBGxvz6d0tgctH9OSdrQd5e8tBALrEx3D/jWOZOrpXJF+CSJtSoZAOq7KqmpjoKI6WVfL6hv1UVTtzc3axbHsBHx+Wzub9R9iSf5SBaUncmN2Xy4b34Lt/XcX6vCL+9vUL6d09gTc25rP9wDFmXNCf7olxAGzeX0x0VBQD0pIi/ApFWoYKhUgd7o6ZUV3tHC6pICUp7vhjB46UcfVDb3KsrIpjFVVUVYf+jwxMT2L2jPOJMuPqX7+JAc9//QJyC0ooKq3k8uE9SNKv/skZSoVC5BS9v7OA+15eT3b/FC4b0YPyymq+9uRyyiqr6NElgcPHyomLiaKotJLyymogdM7HNy8fwr9cNICYOkdYHT5WTnFppc46l3arVQqFmQ0Dng0LDQR+CDwRxLOA7cBn3b0gaHM3MBOoAr7p7guD+HjgcaAT8BJwh7u7mcUH2xsPHARucvftjeWlQiGtZffhEu59YS2vrN3Lw58fT0a3BH70whquH5fJ0J5deHTJVl5dt4+B6UncfH4/bp7Yj87xMWzYW8yX/vQe+4pK+fR5mUwcmMLkgakqGtKutHqPwsyigd3AROB24JC7/8LM7gKS3f17ZjYSeBqYAPQGXgWGunuVmb0H3AG8Q6hQPOTuC8zs68A57n6rmU0HPu3uNzWWiwqFtLYjZZV0rmeIyd15efVe/vDmVlbsPExa5zjO7ZvM21sO0Dk+himjevFszi7KK6tJSYrjre9dRkJsFFsPHGXTvmLmf7CH8krnN587j4TY+i9bUt9QmUhLaJbzerQAAA72SURBVItCcSVwj7tfaGYbgEvdPc/MMoB/uPuwoDeBu/88aLMQ+BGhXsfr7j48iN8ctP9azTruvtTMYoC9QLo3krQKhbQH7+8s4JevbCC3oIQJWSncecVQ+nTvRGlFFW9uOsBXn8jhp58ezYodh/nrilyA4z/6dFN2X4b07Mzq3YVcMCiNQT2S6NElgc7xMdz+1Are23aIL1+YxTmZ3TGDKaN66WRCOW1tcWb2dEK9BYCe7p4HEBSLHkG8D6EeQ43cIFYRLNeN17TZFWyr0swKgVTgQPiTm9ksYBZAv379WugliTTfef2S+cu/TDohnhAbzSdG9GB0n67ct2A9RaWV3DK5P9eO7c05md158NWNPPKPLQB0T4zl/1buOd7WDGKjovj48B784c1tx+OD0pO4aHAavbt3YmbY/EjN96lN+4/w78+tYkyfrtw7bTQAG/cdYeO+Yq4ek0FUlE5ClMaddqEwszjgWuDuplatJ+aNxBtrUzvg/ijwKIR6FE3kIRJRZsZXLhzAt+d+wJg+3fjhNSOPf7j/2xVDSYqLZmzf7lw0OI1N+4+w53AJew6XsuPgUaaM7sW4fslsO3CU8spqdhw8ygOLNvK393dTVFpJfnEZP7hmJFvyj/Avc3LYfbgEdyc6yvhg12Gqqp33dx5m/d5iAI6VVx4/43317kIS46IZmN75eK6lFVX8z+JNvL5+P4eOlvObz41jwoCUtt9pElEt0aP4JLDC3fcF9/eZWUbY0NP+IJ4L9A1rlwnsCeKZ9cTD2+QGQ0/dgEMtkLNIRF1zTm9yC0q47tw+tY6QiomO4huXDTl+f2jPLgzt2eWE9jXnbwzr1YUrR4VODLxn3mr++M9tbNhXzOrdhURHGTMm96eqGm792EDufXEdT7+3iwFpSfzkutE8tzyXBxZtZFy/ZH61eBMvrsojNSmOF795Mb26JbBy12H+be5KtuQf5eIhaRSWhM5+X3DHxcfnUMoqq5j3/h4uH9GD1M7xbNxXzMC0pFqvqbramf3WNsb06cbEgakcK69s8Eq/7s7Bo+WkdY4HoKi0gq4J+jGrSDvtOQozewZY6O5/Cu7fDxwMm8xOcffvmtko4Ck+msxeDAwJJrOXAf8KvEtoMvvX7v6Smd0OjAmbzP6Mu3+2sXw0RyEdVUVVNT+ct5pVuYV06xTLzz8zhv6pH50QWFZZxbJtBUwcmEJsdBQ52w9xw++WApAQG8UXJvbnqfd2Mii9M0N6dGbeB3vo0SWe+64/h0uGpvPmpny++Nh73DyhH9+/egSHj5XzrWdXsmx7Af1TExnfL5nn39/N1edk8Ovp5x0f0vrTW9v4zxfWAtCrawJ7i0q5bHgPHvjs2OMnMNb4zxfW8Jd3d/LyHRezYPVeHlq8ifnfuIhhvU4slo0pq6xixY7DTBqYout7naRWm8w2s0RCcwgD3b0wiKUCc4F+wE7gRnc/FDz2feArQCVwp7svCOLZfHR47ALgX4PDYxOAJ4HzCPUkprv71sZyUqEQOXk/f2kdBcfK+dYVQ8no1on5H+zhjmfep3unWKaO7sVdnxxBt04ffaO/Z95q5izdQWx06Bpa8TFRfPPyIfzxza0cLqng4iHpLNmYz4WDU0nvHE/flET+8OZWJg1M5YJBqXyQW0iPLvH8+Z0duEOUGTdkZ3LPp0ayce8Rpv32n1Q7XDwkjeU7CjhWXsXkgak89dWJtT7w3Z0lmw6QmdyJQcFQWUVVNSt3HaZX1wTuen4Vb20+yB9vyeYTI3seb1dYUsGTS7fzhUn9TyhSp6qiqvqsOohAJ9yJyEkrLq2gc3xMg9/EV+46zLyVu8lMTuSy4T0YkJbEnsMlHDhSxjmZ3fnVqxuZu2wXZsaewhK6JsSy8M5Lal1ocVXuYV5clcfBo+U8tzyXfimJlFVWUVUN15yTweNvbyc6yvjyBVn88Z/b+OKk/vRJ7sSC1XvpHB9NQkw0i9fvp0/3Tiz81iXsLyrlzmdXsiq3EAhdqj4+JoqPD+vBf1w9gp+/tI5bPzaIR97Ywour8rh2bG9+eeNY3tpygLGZ3U/5cONFa/dx5zPv850pw/jyhQOAUPGq+VEt+OjyMWcKFQoRiYjCkgqqqr3RD+KFa/by1Ls7qayu5raPDWZs325M/dWbXDUm1KO59c/LWbxuH9UOY/p041h5JbsKSrgpuy9/fncHE7JSWJVbSHxsFN+dMpxj5ZWM7tONl1fv5an3djJxQApvbjpAXHQU5VXVjMjoyrq8IrJSE9l+8BgJsVHcMD6TL0zqz4Hichav38c/Nx0gvUs8IzO6MrRnF8qqqhmQmsRFQ9KYt3I333p2ZVCMonn9O5eS3iWeBxZt5Mml2/m/2y/kL+/u5IUP9vDqtz92xlzWRYVCRM4o5ZXVxMV89G28tKKKw8cqjvdKqqpDR3L9+IW1zH5rGxcNTuOXN46t1WtZuesw1/32LQBmXjSA93cW0Dkhlke/OJ7rH3mb3IIS7v7kcFbuOszzK3ZTXhW6FEtcTBSTBqZSeKyc9XuLKQsu0QLwvanD+Z/FGzmnT3fuuXYk1/32LT59Xh/u/uQILrzvNY6VV9G7WwJ7CksBePCmsVw2rCc5Ow5x2fAeVFU7B46Un/Rl7KuqnRU7Cyg8VsHA9KRaR6QB5BeXsXTrQXILjvHFSf3pchoT/yoUInJWqqiqZvmOAiZkpZxwPoi7c/kDb1BZ5bzyrUtIiI0+fjHIo2WVVLkfP6Jqf3EpC9fso19KIuP7Jx8/876yqprcghJioo1/ffp93t95mNSkOF6642J6dk3g5wvW8fs3tjIyoytr84r47tRh/NfLGzivX3f2F5UxpGdnYqOjWLR2HzdP6MeW/UdYvrOAOV+ewNHySmb/cxtfvXggGd0T2FtYyqXDehAdZbg7S7ce5Cd/X8favKLjr+niIaGC2Ckuml8sWM9zObnHC9zVYzL4zefOa/bkvQqFiHRIuw4dIzrKTvhd9ubILy7jP/72IV++MIsLBqUBoW/8331uFX9dkcuUUT35/RezWbb9EEN7dOF3S7bwuze24A6jendlzZ4iEmKjSO8Sz+FjFZSUVxEVZccvKglwflYyEweksnDNXjbtP0JGtwS+c+UwBqYn8faWgzz8+mYykxOJi4liXV4Rnz2/Lzef348lm/K5f+EGfjxtFLdMzmrW61OhEBFpJdXVzvPv7+aSIWn06PrRkNKGvcVM+dUS+qcm8sq3LuHVtfsZ0rMzcdFRXPfwWwxK78xjM7JZvC50qllFVTU/eXEdJRVVjOvXnRvH9+VTY3vX+jXGtzYf4Mt/WgYGv//CeD4+vMfxHGbOWUZxaSVzvza5WWfbq1CIiETA/7y6iYuHpjGuX3KteFFpBUlxoZ/qDXekrJLqsCGx+qzcdZiYKGN0n2614oUlFSTERh3/eeBT1RbXehIRkTru+MSQeuMNFYL6rkpc17l9u9cbDz/fpaWdOQf5iohIRKhQiIhIo1QoRESkUSoUIiLSKBUKERFplAqFiIg0SoVCREQapUIhIiKNOuvOzDazfGDHaWwiDTjQQum0pPaYV3vMCZTXqVJep+Zszau/u6fX98BZVyhOl5nlNHQaeyS1x7zaY06gvE6V8jo1HTEvDT2JiEijVChERKRRKhQnejTSCTSgPebVHnMC5XWqlNep6XB5aY5CREQapR6FiIg0SoVCREQapUIRMLOpZrbBzDab2V0RzKOvmb1uZuvMbI2Z3RHEf2Rmu81sZXC7KgK5bTezD4PnzwliKWa2yMw2BX+Tm9pOC+c0LGyfrDSzIjO7MxL7y8xmm9l+M1sdFmtw/5jZ3cH7bYOZTWnjvO43s/VmtsrM/mZm3YN4lpmVhO2337VhTg3+m0V4Xz0bltN2M1sZxNtkXwXP1dDnQtu8v9y9w9+AaGALMBCIAz4ARkYolwxgXLDcBdgIjAR+BHwnwvtpO5BWJ/ZfwF3B8l3AfRH+d9wL9I/E/gIuAcYBq5vaP8G/6QdAPDAgeP9Ft2FeVwIxwfJ9YXllha/Xxvuq3n+zSO+rOo//N/DDttxXwXM19LnQJu8v9ShCJgCb3X2ru5cDzwDTIpGIu+e5+4pguRhYB/SJRC4naRowJ1ieA1wXwVwuB7a4++mcmd9s7r4EOFQn3ND+mQY84+5l7r4N2Ezofdgmebn7K+5eGdx9B8hsjec+lZwaEdF9VcPMDPgs8HRrPHdjGvlcaJP3lwpFSB9gV9j9XNrBh7OZZQHnAe8GoW8EQwWz23qIJ+DAK2a23MxmBbGe7p4HoTcz0CMCedWYTu3/xJHeX9Dw/mlP77mvAAvC7g8ws/fN7A0zu7iNc6nv36y97KuLgX3uviks1ub7qs7nQpu8v1QoQqyeWESPGzazzsBfgTvdvQh4BBgEnAvkEeoCt7UL3X0c8EngdjO7JAI51MvM4oBrgf8NQu1hfzWmXbznzOz7QCXwlyCUB/Rz9/OAbwNPmVnXNkqnoX+zdrGvgJup/UWkzfdVPZ8LDa5aT6zZ+0yFIiQX6Bt2PxPYE6FcMLNYQm+Gv7j78wDuvs/dq9y9GvgDrdT1boy77wn+7gf+FuSwz8wygrwzgP1tnVfgk8AKd98X5Bjx/RVoaP9E/D1nZjOAa4DPezCwHQxVHAyWlxMa2x7aFvk08m/WHvZVDPAZ4NmaWFvvq/o+F2ij95cKRcgyYIiZDQi+mU4H5kcikWAc9DFgnbs/EBbPCFvt08Dqum1bOa8kM+tSs0xoMnQ1of00I1htBjCvLfMKU+vbXqT3V5iG9s98YLqZxZvZAGAI8F5bJWVmU4HvAde6+7GweLqZRQfLA4O8trZRTg39m0V0XwU+Aax399yaQFvuq4Y+F2ir91dbzNifCTfgKkJHEmwBvh/BPC4i1EVcBawMblcBTwIfBvH5QEYb5zWQ0FEUHwBravYRkAosBjYFf1MisM8SgYNAt7BYm+8vQoUqD6gg9I1uZmP7B/h+8H7bAHyyjfPaTGgMu+Y99rtg3euDf98PgBXAp9owpwb/zSK5r4L448CtddZtk30VPFdDnwtt8v7SJTxERKRRGnoSEZFGqVCIiEijVChERKRRKhQiItIoFQoREWmUCoWIiDRKhUJERBr1/wFyeybIEoj14AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(error_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openasr",
   "language": "python",
   "name": "openasr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
