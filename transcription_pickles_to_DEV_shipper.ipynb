{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cfg import Cfg\n",
    "C = Cfg('NIST', 16000, 'pashto', 'dev') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfns=glob('*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import sys, os, tarfile\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pload(fn):\n",
    "    with open(fn, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixup(fn):\n",
    "    return '_'.join(fn.split('_')[2:])[0:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(pred):\n",
    "    return pred.strip().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[(fixup(fn), pload(fn)) for fn in tfns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctms={fixup(fn):[] for fn in tfns}\n",
    "for fn,transcription in results:\n",
    "    key=fn.split('_')\n",
    "    ctm='_'.join(key[0:7])\n",
    "    F='_'.join(key[0:6])\n",
    "    channel=key[6]\n",
    "    for tstart, tend, pred in list(sorted(transcription)):\n",
    "        pred=pred.strip()\n",
    "        if len(pred)==0:\n",
    "            continue\n",
    "        tbeg=tstart\n",
    "        tdur=(tend-tstart)\n",
    "        chnl='1' if channel=='inLine' else '2'\n",
    "        tokens=pred.split(' ')\n",
    "        n_tokens=len(tokens)\n",
    "        token_lengths=np.array([len(token) for token in tokens])\n",
    "        sum_token_lengths=token_lengths.sum()\n",
    "        token_weights=token_lengths/sum_token_lengths\n",
    "        dt=tdur*token_weights\n",
    "        ends = tdur*np.cumsum(token_weights)\n",
    "        tgrid=(ends-ends[0])+tbeg\n",
    "        token_tstart=list(zip(tokens,tgrid))\n",
    "        if ctms[ctm]: start_from = ctms[ctm][-1][2]\n",
    "        for token, tstart, dt in zip(tokens,tgrid,dt):\n",
    "            if token and token[0] not in ['(', '<']:\n",
    "                row=(F,chnl,tstart,dt,token)\n",
    "                ctms[ctm].append(row)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(ctms[ctm],columns=['ctm','channel','start','duration','pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote ../../catskills_openASR20_dev_pashto_001.tgz\n"
     ]
    }
   ],
   "source": [
    "for ctm in ctms:\n",
    "   ctms[ctm].sort()\n",
    "shipping_dir=f'ship/{C.language}/{C.release}'\n",
    "os.system(f'mkdir -p {shipping_dir}')\n",
    "Path(shipping_dir).mkdir(parents=True, exist_ok=True)\n",
    "timestamp=datetime.today().strftime('%Y%m%d_%H%M')\n",
    "for ctm in ctms:\n",
    "   fn=f'{C.shipping_dir}/{ctm}.ctm'\n",
    "   with open(fn,'wt', encoding='utf-8') as f:\n",
    "       for row in ctms[ctm]:\n",
    "           line='\\t'.join([str(x) for x in row])\n",
    "           f.write(f\"{line}\\n\")\n",
    "os.chdir(shipping_dir)\n",
    "tar_fn=f'../../catskills_openASR20_{C.phase}_{C.language}_{C.release}.tgz'\n",
    "with tarfile.open(tar_fn, \"w:gz\") as tar: \n",
    "    for fn in glob('*.ctm'): \n",
    "        tar.add(fn)\n",
    "os.chdir('../../..')\n",
    "print('wrote', tar_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "nemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
